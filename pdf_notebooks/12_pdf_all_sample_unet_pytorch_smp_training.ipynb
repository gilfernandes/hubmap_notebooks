{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "headed-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q git+https://github.com/matjesg/deepflash2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "presidential-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alone-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rapid-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stunning-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np, pandas as pd, segmentation_models_pytorch as smp\n",
    "import albumentations as alb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import cv2, json\n",
    "\n",
    "import torch.utils.data as D\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "derived-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.global_vars import *\n",
    "from datasets.hubdataset import HubDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "norwegian-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "def create_model():\n",
    "    model = smp.Unet(encoder_name=ENCODER_NAME, \n",
    "                     encoder_weights=ENCODER_WEIGHTS,\n",
    "                     activation=None,\n",
    "                     in_channels=CHANNELS, \n",
    "                     classes=2)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-windows",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "diverse-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = smp.losses.DiceLoss(mode='multilabel', from_logits=True)\n",
    "smp.losses.DiceLoss.__name__ = 'Dice Loss'\n",
    "dice_loss.__name__ = 'Dice Loss'\n",
    "\n",
    "jaccard_loss = smp.losses.JaccardLoss(mode='multilabel', from_logits=True)\n",
    "smp.losses.JaccardLoss.__name__ = 'Jaccard Loss'\n",
    "jaccard_loss.__name__ = 'Jaccard Loss'\n",
    "\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "LOSS_FACTOR = 0.2\n",
    "def dice_ce_loss(y_pred, y):\n",
    "    y = y.long()\n",
    "    y_target = y.sum(1)\n",
    "    return dice_loss(y_pred, y) * LOSS_FACTOR + cross_entropy_loss(y_pred, y_target) * (1 - LOSS_FACTOR)\n",
    "#     return dice_loss(y_pred.sigmoid(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "infinite-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG():\n",
    "    \n",
    "    # data paths\n",
    "    data_path = Path('/home/jupyter/data_2/')\n",
    "    data_path_zarr = Path('/home/jupyter/train_scale2')\n",
    "    mask_preproc_dir = '/home/jupyter/masks_scale2'\n",
    "    \n",
    "    # deepflash2 dataset\n",
    "    # scale = 1.5 # data is already downscaled to 2, so absulute downscale is 3\n",
    "    scale = 1 # data is already downscaled to 2, so absulute downscale is 3\n",
    "    tile_shape = (TILE_SHAPE, TILE_SHAPE)\n",
    "    padding = (0,0) # Border overlap for prediction\n",
    "    n_jobs = NUM_WORKERS\n",
    "    sample_mult = 300 # Sample 100 tiles from each image, per epoch\n",
    "    val_length = 500 # Randomly sample 500 validation tiles\n",
    "    stats = np.array([0.61561477, 0.5179343 , 0.64067212]), np.array([0.2915353 , 0.31549066, 0.28647661])\n",
    "    \n",
    "    # deepflash2 augmentation options\n",
    "    zoom_sigma = 0.1\n",
    "    flip = True\n",
    "    max_rotation = 360\n",
    "    deformation_grid_size = (150,150)\n",
    "    deformation_magnitude = (10,10)\n",
    "\n",
    "    # pytorch model (segmentation_models_pytorch)\n",
    "    encoder_name = ENCODER_NAME\n",
    "    encoder_weights = ENCODER_WEIGHTS\n",
    "    in_channels = 3\n",
    "    classes = 2\n",
    "    \n",
    "    # fastai Learner \n",
    "    mixed_precision_training = True\n",
    "    batch_size = 5\n",
    "    weight_decay = 0.01\n",
    "    loss_func = dice_loss\n",
    "#     metrics = [Iou(), Dice_f1()]\n",
    "    max_learning_rate = 1e-3\n",
    "    epochs = 12\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=max_learning_rate, weight_decay=weight_decay)\n",
    "    model = model\n",
    "    arch = 'unet'\n",
    "    \n",
    "    patience = 8\n",
    "    \n",
    "cfg = CONFIG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "compatible-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albumentations augmentations\n",
    "# Inspired by https://www.kaggle.com/iafoss/hubmap-pytorch-fast-ai-starter\n",
    "# deepflash2 augmentations are only affine transformations\n",
    "tfms = alb.OneOf([\n",
    "    alb.HueSaturationValue(10,15,10),\n",
    "    alb.CLAHE(clip_limit=2),\n",
    "    alb.RandomBrightnessContrast(),\n",
    "    alb.OneOf([\n",
    "        alb.MotionBlur(p=0.2),\n",
    "        alb.MedianBlur(blur_limit=3, p=0.1),\n",
    "        alb.Blur(blur_limit=3, p=0.1),\n",
    "    ], p=0.2)\n",
    "], p=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-demand",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unusual-western",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cached slices, files and masks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c37693a6104c8abcba36774b55bcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/rasterio/__init__.py:207: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a58c44c5b1469f848842cb9643c1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/583 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-584c08cdbb6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m }\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrain_ds_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHubDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mds_2_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/hubmap_notebooks/pdf_notebooks/datasets/hubdataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, slices_path, transform, window, overlap, threshold, mode, valid_transform, shifting, rebuild_slices)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         ])\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_normalize_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__copy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hubmap_notebooks/pdf_notebooks/datasets/hubdataset.py\u001b[0m in \u001b[0;36mbuild_normalize_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_normalize_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         self.as_tensor = T.Compose([\n",
      "\u001b[0;32m~/hubmap_notebooks/pdf_notebooks/datasets/hubdataset.py\u001b[0m in \u001b[0;36mget_mean_std\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mchannels_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0mchannels_squared_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mnum_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "root_dir = cfg.data_path\n",
    "slices_path = SLICES_PATH\n",
    "transform = alb.Compose([\n",
    "        alb.Resize(TILE_SHAPE, TILE_SHAPE, p=1.0),\n",
    "        alb.HorizontalFlip(),\n",
    "        alb.VerticalFlip(),\n",
    "        alb.RandomRotate90(),\n",
    "        alb.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=20, p=0.9, \n",
    "                         border_mode=cv2.BORDER_REFLECT),\n",
    "        alb.OneOf([\n",
    "            alb.OpticalDistortion(p=0.4),\n",
    "            alb.GridDistortion(p=.1, border_mode=cv2.BORDER_REFLECT),\n",
    "            alb.IAAPiecewiseAffine(p=0.4),\n",
    "        ], p=0.3),\n",
    "        alb.OneOf([\n",
    "            alb.MotionBlur(p=0.2),\n",
    "            alb.MedianBlur(blur_limit=3, p=0.1),\n",
    "            alb.Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.3),\n",
    "        alb.OneOf([\n",
    "            alb.HueSaturationValue(10,15,10),\n",
    "            alb.CLAHE(clip_limit=3),\n",
    "            alb.RandomBrightnessContrast(),\n",
    "            alb.RandomGamma()\n",
    "        ], p=0.5)\n",
    "    ], p=1.0)\n",
    "\n",
    "valid_transform = alb.Compose([\n",
    "        alb.Resize(TILE_SHAPE, TILE_SHAPE, p=1.0),\n",
    "        alb.HorizontalFlip(),\n",
    "        alb.VerticalFlip(),\n",
    "        alb.RandomRotate90()\n",
    "    ], p=1.0)\n",
    "window = WINDOW\n",
    "overlap = OVERLAP\n",
    "threshold = THRESHOLD\n",
    "ds_2_kwargs = {\n",
    "    'mode': 'train',\n",
    "    'valid_transform': valid_transform,\n",
    "    'shifting': False,\n",
    "    'rebuild_slices': False\n",
    "}\n",
    "\n",
    "train_ds_2 = HubDataset(root_dir, slices_path, transform, window, overlap, threshold, **ds_2_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_img_mask(score, raw_image, index):\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(15,15))\n",
    "    resize_w = 250\n",
    "    resize = 250\n",
    "    ax[0].imshow(score)\n",
    "    ax[0].set_title(f'Mask {index}')\n",
    "    ax[0].set_axis_off()\n",
    "    ax[1].imshow(np.moveaxis(raw_image, 0, -1))\n",
    "    ax[1].set_title(f'Image {index}')\n",
    "    ax[1].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    image, mask = train_ds_2[i]\n",
    "    image.shape, mask.shape, type(image)\n",
    "    plot_img_mask(mask.squeeze().numpy(), image.numpy(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape, mask.shape, mask.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-plant",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_all = np.arange(len(train_ds_2))\n",
    "valid_idx = np.random.choice(len(train_ds_2), int(len(train_ds_2) * 0.05), replace=False )\n",
    "train_idx = np.delete(idx_all, valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = D.Subset(train_ds_2, train_idx)\n",
    "valid_ds_2 = HubDataset(root_dir, slices_path, transform, window, overlap, threshold, **ds_2_kwargs)\n",
    "valid_ds = D.Subset(valid_ds_2, valid_idx)\n",
    "valid_ds.dataset.mode = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    image, mask = valid_ds[i]\n",
    "    print(image.shape, mask.shape, type(image))\n",
    "    plot_img_mask(mask.squeeze().numpy(), image.numpy(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.dataset.is_convert_to_multiclass = True\n",
    "valid_ds.dataset.is_convert_to_multiclass = True\n",
    "\n",
    "train_dl = D.DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.n_jobs)\n",
    "valid_dl = D.DataLoader(valid_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.n_jobs)\n",
    "\n",
    "# train_dl = D.DataLoader(train_ds_2, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.n_jobs)\n",
    "# valid_dl = D.DataLoader(train_ds_2, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.dataset.is_convert_to_multiclass = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-biology",
   "metadata": {},
   "source": [
    "### Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_intersection_cardinality(y_pred, y, dims=(-2, -1)):\n",
    "    x = y_pred\n",
    "    x = torch.argmax(x, 1)\n",
    "    y = torch.argmax(y, 1)\n",
    "    intersection = (x * y).to(torch.int8).sum(dims)\n",
    "    cardinality = (x + y).to(torch.int8).sum(dims)\n",
    "    return intersection, cardinality\n",
    "\n",
    "def dice_metric(y_pred, y, epsilon = 1e-7, dims=(-2, -1)):\n",
    "    intersection, cardinality = calc_intersection_cardinality(y_pred, y)\n",
    "    dc = (2 * intersection + epsilon) / (cardinality + epsilon)\n",
    "    return dc.mean()\n",
    "\n",
    "def iou_metric(y_pred, y, epsilon = 1e-7, dims=(-2, -1)):\n",
    "    intersection, cardinality = calc_intersection_cardinality(y_pred, y)\n",
    "    dc = (intersection + epsilon) / (cardinality - intersection + epsilon)\n",
    "    return dc.mean()\n",
    "\n",
    "dice_metric_2 = smp.utils.metrics.Fscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-tomato",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = [dice_metric, dice_metric_2, iou_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy = CrossEntropyLossFlat(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deepflash2.all import *\n",
    "# cfg.metrics = [Iou(), Dice_f1()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=cfg.batch_size)\n",
    "# if torch.cuda.is_available(): dls.cuda(), model.cuda()\n",
    "# cbs = [SaveModelCallback(monitor='iou')]\n",
    "# learn = Learner(dls, model, metrics=cfg.metrics, wd=cfg.weight_decay, loss_func=cross_entropy, opt_func=ranger, cbs=cbs)\n",
    "# if cfg.mixed_precision_training: learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "# learn.fit_one_cycle(cfg.epochs, lr_max=cfg.max_learning_rate)\n",
    "# learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric = 0\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(cfg.optimizer, max_lr=cfg.max_learning_rate,\n",
    "                                                steps_per_epoch=len(train_dl), epochs=cfg.epochs)\n",
    "\n",
    "for epoch in tqdm(range(cfg.epochs)):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    tbar = tqdm(train_dl, position=0, leave=True)\n",
    "    cfg.model.train()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    iou_sum = 0\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler() # mixed precision support\n",
    "    \n",
    "    for i, data in enumerate(tbar):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(DEVICE), labels.squeeze().float().to(DEVICE)\n",
    "        if inputs.size(0) == labels.size(0):\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                # forward + backward + optimize\n",
    "                outputs = cfg.model(inputs)\n",
    "                loss = jaccard_loss(outputs, labels)\n",
    "                iou = iou_metric(outputs, labels)\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Unscales the gradients of optimizer's assigned params in-place\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            scaler.step(cfg.optimizer)\n",
    "            scale = scaler.get_scale()\n",
    "            scaler.update()\n",
    "            \n",
    "            skip_lr_sched = (scale != scaler.get_scale())\n",
    "            if not skip_lr_sched:\n",
    "                scheduler.step()\n",
    "                \n",
    "            # zero the parameter gradients\n",
    "            cfg.optimizer.zero_grad()\n",
    "            \n",
    "            loss_sum += loss\n",
    "            iou_sum += iou\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        tbar.set_description(f'Train loss - {loss_sum.item() / (i + 1):.5f} iou - {iou_sum.item() / (i + 1):.5f}')\n",
    "\n",
    "    print(f'Train Epoch {epoch}: Training loss {running_loss / len(train_dl):.5F}')\n",
    "        \n",
    "    tbar = tqdm(valid_dl, position=0, leave=True)\n",
    "    cfg.model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    iou_sum = 0\n",
    "    metric_list = [[] for _ in all_metrics]\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tbar):\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(DEVICE), labels.float().to(DEVICE)\n",
    "            \n",
    "            outputs = cfg.model(inputs)\n",
    "            \n",
    "            loss = jaccard_loss(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            for ml, m in zip(metric_list, all_metrics):\n",
    "                m_res = m(outputs, labels)\n",
    "                ml.append(m_res.item())\n",
    "                iou = m_res.item() # iou is the last item\n",
    "                \n",
    "            iou_sum += iou\n",
    "                \n",
    "            tbar.set_description(f'Valid loss - {running_loss / (i + 1):.5f} iou - {iou_sum / (i + 1):.5f}')\n",
    "\n",
    "    dice_metric_mean = np.array(metric_list[0]).mean()\n",
    "    dice_metric_mean_2 = np.array(metric_list[1]).mean()\n",
    "    iou_metric_mean = np.array(metric_list[2]).mean()\n",
    "    \n",
    "    if dice_metric_mean > best_metric:\n",
    "        best_metric = dice_metric_mean\n",
    "        print('Saving Model')\n",
    "        torch.save(cfg.model.state_dict(), 'models/hubmap_best_model_{epoch}_unet_pdf.pth')\n",
    "        \n",
    "    print(f'Valid Epoch {epoch}: Validation loss {running_loss / len(valid_dl):.5F}; dice_metric: {dice_metric_mean:.5F} {dice_metric_mean_2:.5F}; iou: {iou_metric_mean:.5F}')\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = [\n",
    "#     smp.utils.metrics.IoU(),\n",
    "#     dice_metric_2\n",
    "# ]\n",
    "\n",
    "# # create epoch runners \n",
    "# # it is a simple loop of iterating over dataloader`s samples\n",
    "# train_epoch = smp.utils.train.TrainEpoch(\n",
    "#     model, \n",
    "#     loss=jaccard_loss, \n",
    "#     metrics=metrics, \n",
    "#     optimizer=cfg.optimizer,\n",
    "#     device=DEVICE,\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# valid_epoch = smp.utils.train.ValidEpoch(\n",
    "#     model, \n",
    "#     loss=jaccard_loss, \n",
    "#     metrics=metrics, \n",
    "#     device=DEVICE,\n",
    "#     verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_score = 0\n",
    "\n",
    "# for i in range(0, 4):\n",
    "    \n",
    "#     print('\\nEpoch: {}'.format(i))\n",
    "#     train_logs = train_epoch.run(train_dl)\n",
    "#     valid_logs = valid_epoch.run(valid_dl)\n",
    "    \n",
    "#     # do something (save model, change lr, etc.)\n",
    "#     if max_score < valid_logs['iou_score']:\n",
    "#         max_score = valid_logs['iou_score']\n",
    "#         torch.save(model.state_dict(), './best_model.pth')\n",
    "#         print('Model saved!')\n",
    "        \n",
    "#     if i == 25:\n",
    "#         optimizer.param_groups[0]['lr'] = 1e-5\n",
    "#         print('Decrease decoder learning rate to 1e-5!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_metrics = [dice_metric, dice_metric_2, iou_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_lr(optimizer):\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         return param_group['lr']\n",
    "    \n",
    "# def smooth_mask_2(mask, alpha = LABEL_SMOOTH):\n",
    "#     return (1 - alpha) * mask + alpha / 2\n",
    "\n",
    "# def train_epoch(model, dataloader, optim, criterion, scheduler, device=\"cpu\", grad_accu_steps=GRAD_ACCU_STEPS):\n",
    "    \n",
    "#     train_loss = []\n",
    "#     labels = []\n",
    "#     outs = []\n",
    "#     lrs = []\n",
    "    \n",
    "#     tbar = tqdm(dataloader, position=0, leave=True)\n",
    "#     scaler = torch.cuda.amp.GradScaler() # mixed precision support\n",
    "#     scale = None\n",
    "#     for step, (image, target) in enumerate(tbar):\n",
    "        \n",
    "#         image, target = image.to(DEVICE), target.squeeze().float().to(DEVICE)\n",
    "#         target = smooth_mask_2(target)\n",
    "        \n",
    "#         with torch.cuda.amp.autocast():\n",
    "#             output = model(image)\n",
    "#             loss = dice_ce_loss(output, target)\n",
    "#             loss = loss  / grad_accu_steps\n",
    "        \n",
    "#         scaler.scale(loss).backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "#         if (step + 1) % grad_accu_steps == 0:\n",
    "#             scaler.step(optim)\n",
    "#             scale = scaler.get_scale()\n",
    "#             scaler.update()\n",
    "#             optim.zero_grad()\n",
    "        \n",
    "#         skip_lr_sched = (scale != scaler.get_scale())\n",
    "#         if not skip_lr_sched:\n",
    "#             scheduler.step()\n",
    "        \n",
    "#         loss_val = loss.item() * grad_accu_steps\n",
    "#         iou_val = iou_metric(output, target)\n",
    "#         train_loss.append(loss_val)\n",
    "#         lrs.append(get_lr(optim))\n",
    "        \n",
    "#         tbar.set_description(f'loss - {loss_val:.5f} iou: {iou_val:.5f}')\n",
    "        \n",
    "#     print(f'Train loss: {np.array(train_loss).mean()}')\n",
    "#     return train_loss, lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def val_epoch(model, dataloader, criterion, epoch, device=\"cpu\"):\n",
    "#     model.eval()\n",
    "\n",
    "#     valid_loss = []\n",
    "#     num_corrects = 0\n",
    "#     num_total = 0\n",
    "#     labels = []\n",
    "#     outs = []\n",
    "#     metric_list = [[] for _ in all_metrics]\n",
    "\n",
    "#     for item in dataloader:\n",
    "#         image, target = item\n",
    "#         image, target = image.to(DEVICE), target.float().to(DEVICE)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             output = model(image)\n",
    "#             loss = dice_ce_loss(output, target.squeeze())\n",
    "#             for ml, m in zip(metric_list, all_metrics):\n",
    "#                 m_res = m(output, target)\n",
    "#                 ml.append(m_res.item())\n",
    "#         valid_loss.append(loss.item())\n",
    "\n",
    "#     avg_loss = np.array(valid_loss).mean()\n",
    "#     print(f'Epoch {epoch} - valid loss: {avg_loss}')\n",
    "#     dice_metric_mean = np.array(metric_list[0]).mean()\n",
    "#     dice_metric_mean_2 = np.array(metric_list[1]).mean()\n",
    "#     iou_metric_mean = np.array(metric_list[2]).mean()\n",
    "#     return valid_loss, dice_metric_mean, avg_loss, iou_metric_mean, dice_metric_mean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(epochs, train_dl, valid_dl, model, optimizer, scheduler, loss_fn, experiment_name, patience = 6, best_model = 'best_model.pth'):\n",
    "    \n",
    "#     best_model_path = Path(\"models\")\n",
    "#     best_model_path.mkdir(parents=True, exist_ok=True)\n",
    "#     report_path = Path(\"reports\")\n",
    "#     report_path.mkdir(parents=True, exist_ok=True)\n",
    "#     best_loss = 100.0\n",
    "#     best_metric = 0\n",
    "#     train_losses = []\n",
    "#     valid_losses = []\n",
    "#     accumulated_lrs = []\n",
    "#     accumulated_dice_metrics = []\n",
    "#     early_stop_counter = 0\n",
    "#     messages = []\n",
    "\n",
    "#     for epoch in tqdm(range(epochs), position=0, leave=True):\n",
    "#         train_loss, lrs = train_epoch(model, train_dl, optimizer, loss_fn, scheduler, DEVICE)\n",
    "#         valid_loss, dice_metric_mean, avg_loss, iou_metric_mean, dice_metric_mean_2 = val_epoch(model, valid_dl, loss_fn, epoch, DEVICE)\n",
    "#         train_losses += train_loss\n",
    "#         valid_losses.append(np.array(valid_loss).mean())\n",
    "#         accumulated_lrs += lrs\n",
    "#         accumulated_dice_metrics.append(dice_metric_mean)\n",
    "#         if best_metric < dice_metric_mean:\n",
    "#             best_metric = dice_metric_mean\n",
    "#             print('Saving model')\n",
    "#             if torch.cuda.device_count() > 1:\n",
    "#                 torch.save(model.module.state_dict(), best_model_path/best_model)\n",
    "#             else:\n",
    "#                 torch.save(model.state_dict(), best_model_path/best_model)\n",
    "#             early_stop_counter = 0\n",
    "#         else:\n",
    "#             early_stop_counter += 1\n",
    "#         if best_loss > avg_loss:\n",
    "#             best_loss = avg_loss\n",
    "#         print(f'Epoch {epoch} - val best loss {best_loss} dice metric ({dice_metric_mean}, {dice_metric_mean_2}) iou metric ({iou_metric_mean}).')\n",
    "#         messages.append({\n",
    "#             'epoch': epoch,\n",
    "#             'avg_loss': avg_loss,\n",
    "#             'best_loss': best_loss,\n",
    "#             'dice_metric_mean': dice_metric_mean,\n",
    "#             'dice_coeff_mean': dice_metric_mean_2,\n",
    "#             'iou_metric_mean': iou_metric_mean\n",
    "#         })\n",
    "#         with open(report_path/f'{experiment_name}', 'w') as outfile:\n",
    "#             json.dump(messages, outfile)\n",
    "#         if early_stop_counter >= patience:\n",
    "#             print('Stopping early')\n",
    "#             break\n",
    "    \n",
    "#     return train_losses, valid_losses, accumulated_lrs, accumulated_dice_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def learn(experiment_name, lr=1e-3, epochs=10, patience=7):\n",
    "#     scheduler = torch.optim.lr_scheduler.OneCycleLR(cfg.optimizer, max_lr=lr,\n",
    "#                                                     steps_per_epoch=len(train_dl), epochs=epochs)\n",
    "#     train_losses, valid_losses, accumulated_lrs, accumulated_dice_metrics = train(epochs, \n",
    "#                                                                                   train_dl, \n",
    "#                                                                                   valid_dl,\n",
    "#                                                                                   cfg.model,\n",
    "#                                                                                   cfg.optimizer, \n",
    "#                                                                                   scheduler,\n",
    "#                                                                                   cfg.loss_func,\n",
    "#                                                                                   experiment_name,\n",
    "#                                                                                   patience = patience)\n",
    "#     return train_losses, valid_losses, accumulated_lrs, accumulated_dice_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses, valid_losses, accumulated_lrs, accumulated_dice_metrics = learn(f'hub_map_pdf_sample_pytorch_{cfg.arch}_{ENCODER_NAME}_b{cfg.batch_size}', \n",
    "#                                                                               cfg.max_learning_rate, \n",
    "#                                                                               cfg.epochs, \n",
    "#                                                                               cfg.patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-tanzania",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
