{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q git+https://github.com/matjesg/deepflash2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "running-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "subjective-graduation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import zarr, cv2\n",
    "import numpy as np, pandas as pd, segmentation_models_pytorch as smp\n",
    "from deepflash2.all import *\n",
    "from deepflash2.transforms import random_center\n",
    "import albumentations as alb\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "copyrighted-label",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import LovaszSoftmax.pytorch.lovasz_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mobile-sending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from config.global_vars import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accessory-honduras",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ARCH = 'unet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "invalid-debate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model\n",
    "model = smp.Unet(encoder_name=ENCODER_NAME, \n",
    "                 encoder_weights=ENCODER_WEIGHTS, \n",
    "                 in_channels=CHANNELS, \n",
    "                 classes=CLASSES)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "criminal-worse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dangerous-review",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@patch\n",
    "def read_img(self:BaseDataset, file, *args, **kwargs):\n",
    "    return zarr.open(str(file), mode='r')\n",
    "\n",
    "@patch\n",
    "def _name_fn(self:BaseDataset, g):\n",
    "    \"Name of preprocessed and compressed data.\"\n",
    "    return f'{g}'\n",
    "\n",
    "@patch\n",
    "def apply(self:DeformationField, data, offset=(0, 0), pad=(0, 0), order=1):\n",
    "    \"Apply deformation field to image using interpolation\"\n",
    "    outshape = tuple(int(s - p) for (s, p) in zip(self.shape, pad))\n",
    "    coords = [np.squeeze(d).astype('float32').reshape(*outshape) for d in self.get(offset, pad)]\n",
    "    # Get slices to avoid loading all data (.zarr files)\n",
    "    sl = []\n",
    "    for i in range(len(coords)):\n",
    "        cmin, cmax = int(coords[i].min()), int(coords[i].max())\n",
    "        dmax = data.shape[i]\n",
    "        if cmin<0: \n",
    "            cmax = max(-cmin, cmax)\n",
    "            cmin = 0 \n",
    "        elif cmax>dmax:\n",
    "            cmin = min(cmin, 2*dmax-cmax)\n",
    "            cmax = dmax\n",
    "            coords[i] -= cmin\n",
    "        else: coords[i] -= cmin\n",
    "        sl.append(slice(cmin, cmax))    \n",
    "    if len(data.shape) == len(self.shape) + 1:\n",
    "        tile = np.empty((*outshape, data.shape[-1]))\n",
    "        for c in range(data.shape[-1]):\n",
    "            # Adding divide\n",
    "            tile[..., c] = cv2.remap(data[sl[0],sl[1], c]/255, coords[1],coords[0], interpolation=order, borderMode=cv2.BORDER_REFLECT)\n",
    "    else:\n",
    "        tile = cv2.remap(data[sl[0], sl[1]], coords[1], coords[0], interpolation=order, borderMode=cv2.BORDER_REFLECT)\n",
    "    return tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pleasant-turning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@patch\n",
    "def __getitem__(self:RandomTileDataset, idx):\n",
    "    idx = idx % len(self.files)\n",
    "    if torch.is_tensor(idx):\n",
    "        idx = idx.tolist()\n",
    "\n",
    "    img_path = self.files[idx]\n",
    "    img = self.read_img(img_path, divide=self.divide)\n",
    "    n_channels = img.shape[-1]\n",
    "\n",
    "    lbl, pdf  = self.labels[img_path.name], self.pdfs[self._name_fn(img_path.name)]\n",
    "    center = random_center(pdf[:], lbl.shape, TILE_SHAPE)\n",
    "    X = self.gammaFcn(self.deformationField.apply(img, center).flatten()).reshape((*self.tile_shape, n_channels))\n",
    "    Y = self.deformationField.apply(lbl, center, self.padding, 0)\n",
    "    X1 = X.copy()\n",
    "\n",
    "    if self.albumentations_tfms:\n",
    "        augmented = self.albumentations_tfms(image=(X*255).astype('uint8'),mask=Y.astype('uint8'))\n",
    "        X = (augmented['image']/255)\n",
    "        Y = augmented['mask']\n",
    "\n",
    "    X = X.transpose(2, 0, 1).astype('float32')\n",
    "    Y = Y.astype('int64')\n",
    "\n",
    "    if self.loss_weights:\n",
    "        _, W = cv2.connectedComponents((Y > 0).astype('uint8'), connectivity=4)\n",
    "        return  TensorImage(X), TensorMask(Y), torch.Tensor(W)\n",
    "    else:\n",
    "        return  TensorImage(X), TensorMask(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "oriented-depth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@patch\n",
    "def _do_one_batch(self:Learner):\n",
    "    self.pred = self.model(*self.xb)\n",
    "    self('after_pred')\n",
    "    if len(self.yb):\n",
    "        self.loss_grad = self.loss_func(self.pred, *self.yb)\n",
    "        self.loss = self.loss_grad.clone()\n",
    "    self('after_loss')\n",
    "    if not self.training or not len(self.yb): return\n",
    "    self('before_backward')\n",
    "    self.loss_grad.backward()\n",
    "    self._with_events(self.opt.step, 'step', CancelStepException)\n",
    "    self.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-bishop",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "royal-processing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calc_intersection_cardinality(y_pred, y, dims=(-2, -1)):\n",
    "    x = y_pred\n",
    "    x = torch.argmax(x, 1)\n",
    "#     y = torch.argmax(y, 1)\n",
    "    intersection = (x * y).to(torch.int8).sum(dims)\n",
    "    cardinality = (x + y).to(torch.int8).sum(dims)\n",
    "    return intersection, cardinality\n",
    "\n",
    "def dice_metric(y_pred, y, epsilon = 1e-7, dims=(-2, -1)):\n",
    "    intersection, cardinality = calc_intersection_cardinality(y_pred, y)\n",
    "    dc = (2 * intersection + epsilon) / (cardinality + epsilon)\n",
    "    return dc.mean()\n",
    "\n",
    "def iou_metric(y_pred, y, epsilon = 1e-7, dims=(-2, -1)):\n",
    "    intersection, cardinality = calc_intersection_cardinality(y_pred, y)\n",
    "    dc = (intersection + epsilon) / (cardinality - intersection + epsilon)\n",
    "    return dc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-plastic",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "undefined-morocco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CONFIG():\n",
    "    \n",
    "    # data paths\n",
    "    data_path = Path('/home/jupyter/data_2/')\n",
    "    data_path_zarr = Path('/home/jupyter/train_scale2')\n",
    "    mask_preproc_dir = '/home/jupyter/masks_scale2'\n",
    "    \n",
    "    # deepflash2 dataset\n",
    "    # scale = 1.5 # data is already downscaled to 2, so absulute downscale is 3\n",
    "    scale = 1 # data is already downscaled to 2, so absulute downscale is 3\n",
    "    tile_shape = (TILE_SHAPE, TILE_SHAPE)\n",
    "    padding = (0,0) # Border overlap for prediction\n",
    "    n_jobs = NUM_WORKERS\n",
    "    sample_mult = 200 # Sample 100 tiles from each image, per epoch\n",
    "    val_length = 500 # Randomly sample 500 validation tiles\n",
    "    stats = np.array([0.61561477, 0.5179343 , 0.64067212]), np.array([0.2915353 , 0.31549066, 0.28647661])\n",
    "    \n",
    "    # deepflash2 augmentation options\n",
    "    zoom_sigma = 0.1\n",
    "    flip = True\n",
    "    max_rotation = 360\n",
    "    deformation_grid_size = (150,150)\n",
    "    deformation_magnitude = (10,10)\n",
    "\n",
    "    # pytorch model (segmentation_models_pytorch)\n",
    "    encoder_name = ENCODER_NAME\n",
    "    encoder_weights = ENCODER_WEIGHTS\n",
    "    in_channels = 3\n",
    "    classes = 2\n",
    "    \n",
    "    # fastai Learner \n",
    "    mixed_precision_training = True\n",
    "    batch_size = 20\n",
    "    weight_decay = 0.01\n",
    "    loss_func = CrossEntropyLossFlat(axis=1)\n",
    "    metrics = [Iou(), Dice_f1(), dice_metric, iou_metric]\n",
    "    optimizer = ranger\n",
    "    max_learning_rate = 1e-3\n",
    "    epochs = 20\n",
    "    \n",
    "cfg = CONFIG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albumentations augmentations\n",
    "# Inspired by https://www.kaggle.com/iafoss/hubmap-pytorch-fast-ai-starter\n",
    "# deepflash2 augmentations are only affine transformations\n",
    "tfms = alb.OneOf([\n",
    "    alb.HueSaturationValue(10,15,10),\n",
    "    alb.CLAHE(clip_limit=2),\n",
    "    alb.RandomBrightnessContrast(),            \n",
    "    ], p=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(cfg.data_path/'train.csv')\n",
    "df_info = pd.read_csv(cfg.data_path/'HuBMAP-20-dataset_information.csv')\n",
    "\n",
    "files = [x for x in cfg.data_path_zarr.iterdir() if x.is_dir() if not x.name.startswith('.')]\n",
    "label_fn = lambda o: o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {cfg.mask_preproc_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-photography",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "ds_kwargs = {\n",
    "    'tile_shape':cfg.tile_shape,\n",
    "    'padding':cfg.padding,\n",
    "    'scale': cfg.scale,\n",
    "    'n_jobs': cfg.n_jobs, \n",
    "    'preproc_dir': cfg.mask_preproc_dir, \n",
    "    'val_length':cfg.val_length, \n",
    "    'sample_mult':cfg.sample_mult,\n",
    "    'loss_weights':False,\n",
    "    'zoom_sigma': cfg.zoom_sigma,\n",
    "    'flip' : cfg.flip,\n",
    "    'max_rotation': cfg.max_rotation,\n",
    "    'deformation_grid_size' : cfg.deformation_grid_size,\n",
    "    'deformation_magnitude' : cfg.deformation_magnitude,\n",
    "    'albumentations_tfms': tfms\n",
    "}\n",
    "\n",
    "train_ds = RandomTileDataset(files, label_fn=label_fn, **ds_kwargs)\n",
    "valid_ds = TileDataset(files, label_fn=label_fn, **ds_kwargs, is_zarr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LovaszSoftmax.pytorch import lovasz_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader and learner\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=cfg.batch_size, after_batch=Normalize.from_stats(*cfg.stats))\n",
    "if torch.cuda.is_available(): dls.cuda(), model.cuda()\n",
    "cbs = [SaveModelCallback(monitor='iou'), ElasticDeformCallback, GradientClip(max_norm=0.9)]\n",
    "learn = Learner(dls, model, metrics=cfg.metrics, wd=cfg.weight_decay, loss_func=lovasz_losses.lovasz_softmax, opt_func=ranger, cbs=cbs)\n",
    "if cfg.mixed_precision_training: learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "learn.fit_one_cycle(cfg.epochs, lr_max=cfg.max_learning_rate)\n",
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "chicken-victoria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!mv models/model.pth models/hubmap_pdf_sample_lovasz_{ARCH}_{ENCODER_NAME}_b{cfg.batch_size}.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-makeup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
