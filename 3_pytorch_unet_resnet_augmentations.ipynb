{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2 as cv\n",
    "import tifffile as tiff\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "        \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('data')\n",
    "assert DATA_DIR.exists()\n",
    "TRAIN_DATA_DIR = DATA_DIR/'train'\n",
    "assert TRAIN_DATA_DIR.exists()\n",
    "TEST_DATA_DIR = DATA_DIR/'test'\n",
    "assert TEST_DATA_DIR.exists()\n",
    "TRAIN_SAVE_DIR = DATA_DIR/'train_tiles'\n",
    "TEST_SAVE_DIR = DATA_DIR/'test_tiles'\n",
    "TILE_SIZE = 256\n",
    "REDUCE_RATE = 4\n",
    "\n",
    "if not os.path.exists(TRAIN_SAVE_DIR):\n",
    "    os.mkdir(TRAIN_SAVE_DIR)\n",
    "\n",
    "if not os.path.exists(TEST_SAVE_DIR):\n",
    "    os.mkdir(TEST_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pil_images(\n",
    "    images, \n",
    "    masks=None,\n",
    "    labels=None,\n",
    "    columns=5, width=20, height=8, max_images=15, \n",
    "    label_wrap_length=50, label_font_size=9):\n",
    "\n",
    "    if len(images) > max_images:\n",
    "        print(f\"Showing {max_images} images of {len(images)}:\")\n",
    "        images=images[0:max_images]\n",
    "        if masks is not None:\n",
    "            masks= masks[0:max_images]\n",
    "\n",
    "    height = max(height, int(len(images)/columns) * height)\n",
    "    plt.figure(figsize=(width, height))\n",
    "    \n",
    "    if masks is not None:\n",
    "        for i, (image, mask) in enumerate(zip(images,masks)):\n",
    "            plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.imshow(mask, cmap='coolwarm', alpha=0.5)\n",
    "            \n",
    "            if labels is not None:\n",
    "                plt.title(labels[i], fontsize=label_font_size); \n",
    "            \n",
    "    else:\n",
    "        for i, image in enumerate(images):\n",
    "            plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "            plt.imshow(image)\n",
    "        \n",
    "            if labels is not None:\n",
    "                plt.title(labels[i], fontsize=label_font_size); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (np.random.rand(9) > 0.5).astype(np.int8)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask2rle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle2mask(mask_rle, shape=(1600,256)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (width,height) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_tile_contains_info(img, pixel_limits, content_threshold, expected_shape):\n",
    "    \"\"\"\n",
    "    img: np.array\n",
    "    pixel_limits: tuple\n",
    "    content_threshold: float percents\n",
    "    expected_shape: tuple\n",
    "    \"\"\"\n",
    "    \n",
    "    left_limit = np.prod(img > pixel_limits[0], axis=-1)\n",
    "    right_limit =  np.prod(img < pixel_limits[1], axis=-1)\n",
    "\n",
    "    if img.shape != expected_shape:\n",
    "        return False, 0.\n",
    "\n",
    "    percent_of_pixels = np.sum(left_limit*right_limit) / (img.shape[0] * img.shape[1])\n",
    "    return  percent_of_pixels > content_threshold, percent_of_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_train_tiles(sample_img_path, rle_mask_sample, idx):\n",
    "    print(idx)\n",
    "    sample_image = tiff.imread(sample_img_path)\n",
    "    \n",
    "    if idx in ['e79de561c', '095bf7a1f', '54f2eec69', '1e2425f28']:\n",
    "        sample_image = np.transpose(sample_image.squeeze(), (1,2,0))\n",
    "\n",
    "        \n",
    "    sample_mask = rle2mask(rle_mask_sample, (sample_image.shape[1], sample_image.shape[0]))\n",
    "    print(f\"Original Tiff image shape: {sample_image.shape}\")\n",
    "    \n",
    "    pad0 = (REDUCE_RATE*TILE_SIZE - sample_image.shape[0]%(REDUCE_RATE*TILE_SIZE))%(REDUCE_RATE*TILE_SIZE)\n",
    "    pad1 = (REDUCE_RATE*TILE_SIZE - sample_image.shape[1]%(REDUCE_RATE*TILE_SIZE))%(REDUCE_RATE*TILE_SIZE)\n",
    "    \n",
    "    sample_image = np.pad(sample_image,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],\n",
    "                   constant_values=0)\n",
    "    sample_mask = np.pad(sample_mask,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2]],\n",
    "                  constant_values=0)\n",
    "        \n",
    "    sample_image = cv.resize(sample_image,(sample_image.shape[1]//REDUCE_RATE,sample_image.shape[0]//REDUCE_RATE),\n",
    "                             interpolation = cv.INTER_AREA)\n",
    "    \n",
    "    sample_mask = cv.resize(sample_mask,(sample_mask.shape[1]//REDUCE_RATE,sample_mask.shape[0]//REDUCE_RATE),\n",
    "                             interpolation = cv.INTER_AREA)\n",
    "    \n",
    "    print(f\"Reduced Tiff image shape: {sample_image.shape}\")\n",
    "    \n",
    "    tiles, masks, paths = [], [], []\n",
    "    skipped_count = 0\n",
    "    for x in range(0, sample_image.shape[0], TILE_SIZE):\n",
    "        for y in range(0,sample_image.shape[1], TILE_SIZE):\n",
    "            sub_image = np.float32(sample_image[x:x + TILE_SIZE,y:y + TILE_SIZE])\n",
    "            sub_mask = sample_mask[x:x + TILE_SIZE,y:y + TILE_SIZE]\n",
    "            if is_tile_contains_info(sub_image, (50, 220), 0.7, (TILE_SIZE,TILE_SIZE, 3))[0]:\n",
    "                tiles.append(sub_image)\n",
    "                masks.append(sub_mask)\n",
    "            else:\n",
    "                skipped_count += 1\n",
    "    print(f'Skipped {skipped_count}')\n",
    "    \n",
    "    if not os.path.exists(os.path.join(TRAIN_SAVE_DIR, idx)):\n",
    "        os.mkdir(os.path.join(TRAIN_SAVE_DIR, idx))\n",
    "\n",
    "    count = 0\n",
    "    for tile,mask in zip(tiles,masks):\n",
    "        cv.imwrite(os.path.join(TRAIN_SAVE_DIR, idx, f\"img_{count}.png\"), tile)\n",
    "        cv.imwrite(os.path.join(TRAIN_SAVE_DIR, idx, f\"mask_{count}.png\"), mask)\n",
    "        paths.append((os.path.join(TRAIN_SAVE_DIR, idx, f\"img_{count}.png\"), \n",
    "                      os.path.join(TRAIN_SAVE_DIR, idx, f\"mask_{count}.png\")))\n",
    "\n",
    "        count += 1\n",
    "            \n",
    "    print(f\"Length tiles\", len(tiles))\n",
    "    gc.collect()\n",
    "    \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_test_tiles(sample_img_path, idx):\n",
    "    print(idx)\n",
    "    sample_image = tiff.imread(sample_img_path)\n",
    "    \n",
    "    if idx in ['26dc41664', 'c68fe75ea']:\n",
    "        sample_image = np.transpose(sample_image.squeeze(), (1,2,0))\n",
    "\n",
    "    print(f\"Original Tiff image shape: {sample_image.shape}\")\n",
    "    \n",
    "    pad0 = (REDUCE_RATE*TILE_SIZE - sample_image.shape[0]%(REDUCE_RATE*TILE_SIZE))%(REDUCE_RATE*TILE_SIZE)\n",
    "    pad1 = (REDUCE_RATE*TILE_SIZE - sample_image.shape[1]%(REDUCE_RATE*TILE_SIZE))%(REDUCE_RATE*TILE_SIZE)\n",
    "    \n",
    "    sample_image = np.pad(sample_image,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],\n",
    "                   constant_values=0)\n",
    "    \n",
    "    sample_image = cv.resize(sample_image,(sample_image.shape[1]//REDUCE_RATE,sample_image.shape[0]//REDUCE_RATE),\n",
    "                             interpolation = cv.INTER_AREA)\n",
    "    \n",
    "    print(f\"Reduced Tiff image shape: {sample_image.shape}\")\n",
    "    \n",
    "    tiles, paths = [], []\n",
    "    for x in range(0,sample_image.shape[0],TILE_SIZE):\n",
    "        for y in range(0,sample_image.shape[1],TILE_SIZE):\n",
    "            sub_image = np.float32(sample_image[x:x+TILE_SIZE,y:y+TILE_SIZE])\n",
    "            tiles.append(sub_image)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(TEST_SAVE_DIR, idx)):\n",
    "        os.mkdir(os.path.join(TEST_SAVE_DIR, idx))\n",
    "\n",
    "    count = 0\n",
    "    for tile in tiles:\n",
    "        cv.imwrite(os.path.join(TEST_SAVE_DIR, idx, f\"img_{count}.png\"), tile)\n",
    "        paths.append(os.path.join(TEST_SAVE_DIR, idx, f\"img_{count}.png\"))\n",
    "        count += 1\n",
    "            \n",
    "    print(f\"Length tiles\", len(tiles))\n",
    "    gc.collect()\n",
    "    \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2f6ecfcdf</td>\n",
       "      <td>296084587 4 296115835 6 296115859 14 296147109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaa6a05cc</td>\n",
       "      <td>30989109 59 31007591 64 31026074 68 31044556 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cb2d976f4</td>\n",
       "      <td>78144363 5 78179297 15 78214231 25 78249165 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0486052bb</td>\n",
       "      <td>101676003 6 101701785 8 101727568 9 101753351 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e79de561c</td>\n",
       "      <td>7464094 14 7480273 41 7496453 67 7512632 82 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>095bf7a1f</td>\n",
       "      <td>113430380 22 113468538 67 113506697 111 113544...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54f2eec69</td>\n",
       "      <td>124601765 36 124632133 109 124662536 147 12469...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1e2425f28</td>\n",
       "      <td>49453112 7 49479881 22 49506657 31 49533433 40...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           encoding\n",
       "0  2f6ecfcdf  296084587 4 296115835 6 296115859 14 296147109...\n",
       "1  aaa6a05cc  30989109 59 31007591 64 31026074 68 31044556 7...\n",
       "2  cb2d976f4  78144363 5 78179297 15 78214231 25 78249165 35...\n",
       "3  0486052bb  101676003 6 101701785 8 101727568 9 101753351 ...\n",
       "4  e79de561c  7464094 14 7480273 41 7496453 67 7512632 82 75...\n",
       "5  095bf7a1f  113430380 22 113468538 67 113506697 111 113544...\n",
       "6  54f2eec69  124601765 36 124632133 109 124662536 147 12469...\n",
       "7  1e2425f28  49453112 7 49479881 22 49506657 31 49533433 40..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'), encoding='utf-8')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b9a3865fc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b2dc8411c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26dc41664</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c68fe75ea</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afa5e8098</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  predicted\n",
       "0  b9a3865fc        NaN\n",
       "1  b2dc8411c        NaN\n",
       "2  26dc41664        NaN\n",
       "3  c68fe75ea        NaN\n",
       "4  afa5e8098        NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv(DATA_DIR/'sample_submission.csv')\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/train/2f6ecfcdf.tiff', 'data/train/aaa6a05cc.tiff', 'data/train/cb2d976f4.tiff', 'data/train/0486052bb.tiff', 'data/train/e79de561c.tiff', 'data/train/095bf7a1f.tiff', 'data/train/54f2eec69.tiff', 'data/train/1e2425f28.tiff']\n",
      "['data/test/b9a3865fc.tiff', 'data/test/b2dc8411c.tiff', 'data/test/26dc41664.tiff', 'data/test/c68fe75ea.tiff', 'data/test/afa5e8098.tiff']\n"
     ]
    }
   ],
   "source": [
    "train_img_paths = [os.path.join(TRAIN_DATA_DIR, item + '.tiff') for item in train_df['id']]\n",
    "test_img_paths = [os.path.join(TEST_DATA_DIR, item + '.tiff') for item in sample_df['id']]\n",
    "\n",
    "print(train_img_paths)\n",
    "print(test_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2f6ecfcdf\n",
      "Original Tiff image shape: (31278, 25794, 3)\n",
      "Reduced Tiff image shape: (7936, 6656, 3)\n",
      "Skipped 554\n",
      "Length tiles 252\n",
      "aaa6a05cc\n",
      "Original Tiff image shape: (18484, 13013, 3)\n",
      "Reduced Tiff image shape: (4864, 3328, 3)\n",
      "Skipped 160\n",
      "Length tiles 87\n",
      "cb2d976f4\n",
      "Original Tiff image shape: (34940, 49548, 3)\n",
      "Reduced Tiff image shape: (8960, 12544, 3)\n",
      "Skipped 1154\n",
      "Length tiles 561\n",
      "0486052bb\n",
      "Original Tiff image shape: (25784, 34937, 3)\n",
      "Reduced Tiff image shape: (6656, 8960, 3)\n",
      "Skipped 620\n",
      "Length tiles 290\n",
      "e79de561c\n",
      "Original Tiff image shape: (16180, 27020, 3)\n",
      "Reduced Tiff image shape: (4096, 6912, 3)\n",
      "Skipped 59\n",
      "Length tiles 373\n",
      "095bf7a1f\n",
      "Original Tiff image shape: (38160, 39000, 3)\n",
      "Reduced Tiff image shape: (9728, 9984, 3)\n",
      "Skipped 433\n",
      "Length tiles 1049\n",
      "54f2eec69\n",
      "Original Tiff image shape: (30440, 22240, 3)\n",
      "Reduced Tiff image shape: (7680, 5632, 3)\n",
      "Skipped 106\n",
      "Length tiles 554\n",
      "1e2425f28\n",
      "Original Tiff image shape: (26780, 32220, 3)\n",
      "Reduced Tiff image shape: (6912, 8192, 3)\n",
      "Skipped 278\n",
      "Length tiles 586\n",
      "Length of all samples: 3752\n",
      "CPU times: user 2min 46s, sys: 18.8 s, total: 3min 5s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_train_paths = []\n",
    "for idx, train_img_path in enumerate(train_img_paths):\n",
    "    paths = extract_train_tiles(train_img_path, \n",
    "                                train_df['encoding'].values[idx], \n",
    "                                train_df['id'].values[idx])\n",
    "    all_train_paths.extend(paths)\n",
    "    \n",
    "print(\"Length of all samples:\", len(all_train_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b9a3865fc\n",
      "Original Tiff image shape: (31295, 40429, 3)\n",
      "Reduced Tiff image shape: (7936, 10240, 3)\n",
      "Length tiles 1240\n",
      "b2dc8411c\n",
      "Original Tiff image shape: (14844, 31262, 3)\n",
      "Reduced Tiff image shape: (3840, 7936, 3)\n",
      "Length tiles 465\n",
      "26dc41664\n",
      "Original Tiff image shape: (38160, 42360, 3)\n",
      "Reduced Tiff image shape: (9728, 10752, 3)\n",
      "Length tiles 1596\n",
      "c68fe75ea\n",
      "Original Tiff image shape: (26840, 49780, 3)\n",
      "Reduced Tiff image shape: (6912, 12544, 3)\n",
      "Length tiles 1323\n",
      "afa5e8098\n",
      "Original Tiff image shape: (36800, 43780, 3)\n",
      "Reduced Tiff image shape: (9216, 11008, 3)\n",
      "Length tiles 1548\n",
      "Length of all samples: 6172\n",
      "CPU times: user 1min 24s, sys: 18.3 s, total: 1min 43s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_test_paths = []\n",
    "for idx, test_img_path in enumerate(test_img_paths):\n",
    "    paths = extract_test_tiles(test_img_path, \n",
    "                               sample_df['id'].values[idx])\n",
    "    all_test_paths.extend(paths)\n",
    "    \n",
    "print(\"Length of all samples:\", len(all_test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
