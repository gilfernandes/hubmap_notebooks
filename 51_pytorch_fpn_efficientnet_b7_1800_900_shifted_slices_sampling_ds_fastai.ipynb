{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U git+https://github.com/qubvel/segmentation_models.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fastai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.losses.constants import BINARY_MODE, MULTICLASS_MODE, MULTILABEL_MODE\n",
    "from segmentation_models_pytorch.losses._functional import soft_jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys, os, random, time, json\n",
    "import numba, cv2, gc\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from segmentation_models_pytorch import FPN\n",
    "from segmentation_models_pytorch import Unet\n",
    "from segmentation_models_pytorch import MAnet\n",
    "from segmentation_models_pytorch import Linknet\n",
    "from segmentation_models_pytorch import PAN\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed = 42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "# set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/jupyter/data_2/\n",
    "DATA_PATH = Path('/home/jupyter/data_2/')\n",
    "assert DATA_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/jupyter/data/\n",
    "DATA_PATH_ORIG = Path('/home/jupyter/data/')\n",
    "assert DATA_PATH_ORIG.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_PATH = Path('/home/jupyter/reports')\n",
    "if not REPORT_PATH.exists():\n",
    "    os.makedirs(REPORT_PATH)\n",
    "assert REPORT_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_fold_0\n",
      "37_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_fold_1\n",
      "37_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_fold_2\n",
      "37_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_fold_3\n",
      "37_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_0\n",
      "37_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_1\n",
      "37_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_2\n",
      "37_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_3\n",
      "39_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_advprop_fold_0\n",
      "39_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_advprop_fold_1\n",
      "39_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_advprop_fold_2\n",
      "39_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_advprop_fold_3\n",
      "40_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_1\n",
      "40_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_2\n",
      "40_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_3\n",
      "40_pytorch_linknet_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_0\n",
      "40_pytorch_linknet_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_1\n",
      "40_pytorch_linknet_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_2\n",
      "40_pytorch_linknet_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_3\n",
      "40_pytorch_pan_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_0\n",
      "40_pytorch_unet_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_new_data_fold_0\n",
      "43_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_b12_fold_0\n",
      "43_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_b12_fold_1\n",
      "43_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_b12_fold_2\n",
      "43_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_b12_fold_3\n",
      "43_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_b3_fold_0\n",
      "43_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_double_data_fold_0\n",
      "43_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_double_data_fold_1\n",
      "43_pytorch_fpn_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_double_data_fold_2\n",
      "43_pytorch_fpn_timm-efficientnet-b8_1344_672_shifted_slices_groupkfold_smooth_b5_fold_0\n",
      "43_pytorch_linknet_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_b12_fold_0\n",
      "43_pytorch_unet_efficientnet_b7_2048_1024_shifted_slices_groupkfold_smooth_b6_fold_0\n",
      "43_pytorch_unet_efficientnet_b7_2048_1024_shifted_slices_groupkfold_smooth_b6_fold_1\n",
      "43_pytorch_unet_efficientnet_b7_2048_1024_shifted_slices_groupkfold_smooth_b6_fold_2\n",
      "43_pytorch_unet_efficientnet_b7_2048_1024_shifted_slices_groupkfold_smooth_b6_fold_3\n",
      "48_pytorch_fpn_timm-efficientnet-b8_1536_768_shifted_slices_groupkfold_smooth_b7_fold_0\n",
      "48_pytorch_fpn_timm-efficientnet-b8_1536_768_shifted_slices_groupkfold_smooth_b8_fold_0\n",
      "49_pytorch_fpn_efficientnet-b7_1792_896_shifted_slices_groupkfold_smooth_b6_fold_0\n",
      "49_pytorch_fpn_efficientnet-b7_1792_896_shifted_slices_groupkfold_smooth_b6_fold_1\n",
      "49_pytorch_fpn_efficientnet-b7_1792_896_shifted_slices_groupkfold_smooth_b6_fold_2\n"
     ]
    }
   ],
   "source": [
    "!ls {REPORT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCH = 'fpn' # fpn, manet, linknet, pan, unet\n",
    "\n",
    "WINDOW = 1792 # tile size\n",
    "MIN_OVERLAP = 32\n",
    "NEW_SIZE = WINDOW // 2 # size after re-size which are fed to the model\n",
    "\n",
    "WINDOW_2 = 1024 # tile size\n",
    "NEW_SIZE_2 = 1024 # size after re-size which are fed to the model\n",
    "\n",
    "THRESHOLD = (WINDOW ** 2 * 1) // 100  # 5% of the image has to be positive\n",
    "CONTENT_THRESHOLD = 0.001\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "FOLDS = 4\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "ENCODER_NAME = 'efficientnet-b7'\n",
    "\n",
    "LR = 1e-3\n",
    "WD = 1e-3\n",
    "LABEL_SMOOTH = 0.01\n",
    "GRAD_ACCU_STEPS = 1\n",
    "BEST_MODEL = f'best_model_{ARCH}_{ENCODER_NAME}_{WINDOW}_{NEW_SIZE}_double_shift_{ENCODER_NAME}.pth'\n",
    "\n",
    "RESET_IMAGES = False\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "SLICES_PATH = Path('/home/jupyter/ds_cache')\n",
    "SLICES_PATH_2 = Path('/home/jupyter/ds_cache_high_res')\n",
    "\n",
    "EPOCHS = 5\n",
    "PATIENCE = 10\n",
    "\n",
    "EXPERIMENT_NAME = f'51_fastai_{ARCH}_{ENCODER_NAME}_{WINDOW}_{NEW_SIZE}_groupkfold_b{BATCH_SIZE}'\n",
    "SLICE_NUMBER = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape=(256, 256)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    splits = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (splits[0:][::2], splits[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype='uint8')\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo: hi] = 1\n",
    "    return img.reshape(shape, order='F') # Fortran order reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def rle_numba(pixels):\n",
    "    size = len(pixels)\n",
    "    points = []\n",
    "    if pixels[0] == 1: points.append(1)\n",
    "    for i in range(1, size):\n",
    "        if pixels[i] != pixels[i-1]:\n",
    "            if len(points) % 2 == 0:\n",
    "                points.append(i+1)\n",
    "            else:\n",
    "                points.append(i+1 - points[-1])\n",
    "    if pixels[-1] == 1: points.append(size-points[-1]+1)    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_numba_encode(image):\n",
    "    pixels = image.flatten(order = 'F')\n",
    "    points = rle_numba(pixels)\n",
    "    return ' '.join(str(x) for x in points)\n",
    "\n",
    "def make_grid(shape, window=256, min_overlap=32):\n",
    "    \"\"\"\n",
    "        Return Array of size (N,4), where N - number of tiles,\n",
    "        2nd axis represente slices: x1,x2,y1,y2 \n",
    "    \"\"\"\n",
    "    x, y = shape\n",
    "    nx = x // (window - min_overlap) + 1\n",
    "    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n",
    "    x1[-1] = x - window\n",
    "    x2 = (x1 + window).clip(0, x)\n",
    "    ny = y // (window - min_overlap) + 1\n",
    "    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n",
    "    y1[-1] = y - window\n",
    "    y2 = (y1 + window).clip(0, y)\n",
    "    slices = np.zeros((nx,ny, 4), dtype=np.int64)\n",
    "    \n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            slices[i,j] = x1[i], x2[i], y1[j], y2[j]    \n",
    "    return slices.reshape(nx*ny,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2f6ecfcdf</th>\n",
       "      <td>296084587 4 296115835 6 296115859 14 296147109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8242609fa</th>\n",
       "      <td>96909968 56 96941265 60 96972563 64 97003861 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa6a05cc</th>\n",
       "      <td>30989109 59 31007591 64 31026074 68 31044556 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb2d976f4</th>\n",
       "      <td>78144363 5 78179297 15 78214231 25 78249165 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b9a3865fc</th>\n",
       "      <td>61271840 4 61303134 13 61334428 22 61365722 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2dc8411c</th>\n",
       "      <td>56157731 21 56172571 45 56187411 51 56202252 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0486052bb</th>\n",
       "      <td>101676003 6 101701785 8 101727568 9 101753351 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e79de561c</th>\n",
       "      <td>7334642 14 7350821 41 7367001 67 7383180 82 73...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>095bf7a1f</th>\n",
       "      <td>113277795 21 113315936 53 113354083 87 1133922...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54f2eec69</th>\n",
       "      <td>124967057 36 124997425 109 125027828 147 12505...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4ef6695ce</th>\n",
       "      <td>137041956 58 137081912 65 137121869 72 1371618...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26dc41664</th>\n",
       "      <td>245832956 28 245869925 2 245871115 33 24590808...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c68fe75ea</th>\n",
       "      <td>21256809 3 21283644 10 21310479 17 21337315 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afa5e8098</th>\n",
       "      <td>65837968 7 65874765 11 65874827 12 65911562 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e2425f28</th>\n",
       "      <td>49453112 7 49479881 22 49506657 31 49533433 40...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    encoding\n",
       "id                                                          \n",
       "2f6ecfcdf  296084587 4 296115835 6 296115859 14 296147109...\n",
       "8242609fa  96909968 56 96941265 60 96972563 64 97003861 6...\n",
       "aaa6a05cc  30989109 59 31007591 64 31026074 68 31044556 7...\n",
       "cb2d976f4  78144363 5 78179297 15 78214231 25 78249165 35...\n",
       "b9a3865fc  61271840 4 61303134 13 61334428 22 61365722 30...\n",
       "b2dc8411c  56157731 21 56172571 45 56187411 51 56202252 5...\n",
       "0486052bb  101676003 6 101701785 8 101727568 9 101753351 ...\n",
       "e79de561c  7334642 14 7350821 41 7367001 67 7383180 82 73...\n",
       "095bf7a1f  113277795 21 113315936 53 113354083 87 1133922...\n",
       "54f2eec69  124967057 36 124997425 109 125027828 147 12505...\n",
       "4ef6695ce  137041956 58 137081912 65 137121869 72 1371618...\n",
       "26dc41664  245832956 28 245869925 2 245871115 33 24590808...\n",
       "c68fe75ea  21256809 3 21283644 10 21310479 17 21337315 22...\n",
       "afa5e8098  65837968 7 65874765 11 65874827 12 65911562 15...\n",
       "1e2425f28  49453112 7 49479881 22 49506657 31 49533433 40..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(DATA_PATH / 'train.csv', index_col=[0])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def reset_slices_path():\n",
    "    shutil.rmtree(SLICES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Used to filter tiles with enough color information in it\n",
    "def is_tile_contains_info(img, expected_shape, pixel_limits = (50, 220), content_threshold = CONTENT_THRESHOLD):\n",
    "    \"\"\"\n",
    "    img: np.array\n",
    "    pixel_limits: tuple\n",
    "    content_threshold: float percents\n",
    "    expected_shape: tuple\n",
    "    \"\"\"\n",
    "    \n",
    "    left_limit = np.prod(img > pixel_limits[0], axis=-1)\n",
    "    right_limit =  np.prod(img < pixel_limits[1], axis=-1)\n",
    "\n",
    "    if img.shape != expected_shape:\n",
    "        print('img.shape != expected_shape', img.shape)\n",
    "        return False, 0.\n",
    "\n",
    "    percent_of_pixels = np.sum(left_limit*right_limit) / (img.shape[0] * img.shape[1])\n",
    "    return  percent_of_pixels > content_threshold, percent_of_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "identity = None\n",
    "stats = np.array([0.6276, 0.4468, 0.6769]), np.array([0.1446, 0.2113, 0.1233])\n",
    "# normalize_transform = T.Normalize([0.625, 0.448, 0.688], [0.131, 0.177, 0.101])\n",
    "# normalize_transform = T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# normalize_transform = T.Normalize([0.65459856,0.48386562,0.69428385], [0.15167958,0.23584107,0.13146145])\n",
    "\n",
    "def read_from_slice(dataset, layers, x1, x2, y1, y2, window):\n",
    "    if dataset.count == 3:\n",
    "        image = dataset.read([1,2,3],\n",
    "                    window=Window.from_slices((x1,x2),(y1,y2)))\n",
    "        image = np.moveaxis(image, 0, -1)\n",
    "    else:\n",
    "        image = np.zeros((window, window, 3), dtype=np.uint8)\n",
    "        for fl in range(3):\n",
    "            try:\n",
    "                image[:,:,fl] = layers[fl].read(window=Window.from_slices((x1,x2),(y1,y2)))\n",
    "            except ValueError as e:\n",
    "                print('ValueError', e, dataset.shape, x1, x2, y1, y2)\n",
    "                raise e\n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "def extract_layers(dataset, filepath):\n",
    "    layers = None\n",
    "    if dataset.count != 3:\n",
    "        layers = [rasterio.open(subd) for subd in dataset.subdatasets]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESET_IMAGES:\n",
    "    reset_slices_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/jupyter/ds_cache’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir {SLICES_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HubDataset(D.Dataset):\n",
    "    def __init__(self, root_dir, slices_path, transform, valid_transform=None, mode='train', \n",
    "                 window=WINDOW, overlap=MIN_OVERLAP, threshold=THRESHOLD, slice_number=SLICE_NUMBER):\n",
    "        self.path, self.slices_path = root_dir, slices_path\n",
    "        assert self.path.exists()\n",
    "        self.overlap, self.window, self.transform, self.valid_transform, self.threshold, self.slice_number = overlap, window, transform, valid_transform, threshold, slice_number\n",
    "        self.mode = mode\n",
    "        self.csv = pd.read_csv(self.path/'train.csv', index_col=[0])\n",
    "        self.build_slices()\n",
    "        self.len = len(self.slices)\n",
    "        self.set_normalize_transform(stats)\n",
    "        self.do_transform = True\n",
    "        \n",
    "    def __copy__(self):\n",
    "        new_ds = type(self)(\n",
    "            self.path,\n",
    "            self.slices_path,\n",
    "            self.transform,\n",
    "            valid_transform=self.valid_transform,\n",
    "            mode=self.mode,\n",
    "            window=self.window,\n",
    "            overlap=self.overlap,\n",
    "            threshold=self.threshold\n",
    "        )\n",
    "        new_ds.masks = self.masks\n",
    "        new_ds.files = self.files\n",
    "        new_ds.slices = self.slices\n",
    "        new_ds.skipped = self.skipped\n",
    "        return new_ds\n",
    "    \n",
    "    def set_normalize_transform(self, stats):\n",
    "        self.as_tensor = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(stats[0], stats[1]),\n",
    "        ])\n",
    "    \n",
    "    def build_masks(self):\n",
    "        for i, filename in tqdm(enumerate(self.csv.index), total = len(self.csv)):\n",
    "            filepath = self.path/'train'/f'{filename}.tiff'\n",
    "            with rasterio.open(filepath) as dataset:\n",
    "                self.masks.append(rle_decode(self.csv.loc[filename, 'encoding'], dataset.shape))\n",
    "        \n",
    "    def build_slices(self):\n",
    "        self.masks = []; self.files = []; self.slices = []\n",
    "        self.skipped = 0\n",
    "        slices_path = self.slices_path/f'slices.pkl'\n",
    "        files_path = self.slices_path/f'files.pkl'\n",
    "        if not slices_path.exists():\n",
    "            for i, filename in tqdm(enumerate(self.csv.index), total = len(self.csv)):\n",
    "                filepath = self.path/'train'/f'{filename}.tiff'\n",
    "                assert filepath.exists()\n",
    "                self.files.append(filepath)\n",
    "                with rasterio.open(filepath) as dataset:\n",
    "                    self.build_slice_random(dataset, filename, i)\n",
    "                print(f'Finished {filename}')\n",
    "            with open(slices_path, \"wb\") as filehandler:\n",
    "                pickle.dump(self.slices, filehandler)\n",
    "            with open(files_path, \"wb\") as filehandler:\n",
    "                pickle.dump(self.files, filehandler)\n",
    "            \n",
    "        else:\n",
    "            print('Reading cached slices, files and masks')\n",
    "            with open(slices_path,'rb') as file:\n",
    "                self.slices = pickle.load(file)\n",
    "            with open(files_path,'rb') as file:\n",
    "                self.files = pickle.load(file)\n",
    "        self.build_masks()\n",
    "                \n",
    "    def build_slice_random(self, dataset, filename, i):\n",
    "        dataset_shape = dataset.shape\n",
    "        self.masks.append(rle_decode(self.csv.loc[filename, 'encoding'], dataset_shape))\n",
    "        filename = DATA_PATH/'train'/f'2f6ecfcdf.tiff'\n",
    "        assert filename.exists()\n",
    "        mask = self.masks[-1]\n",
    "        layers = extract_layers(dataset, filename)\n",
    "        shape = dataset.shape\n",
    "        assert mask.shape == shape\n",
    "        shape_minus_size = (shape[0] - self.window, shape[1] - self.window)\n",
    "        slice_counter = 0\n",
    "        set_x = set()\n",
    "        set_y = set()\n",
    "        while slice_counter < self.slice_number:\n",
    "            x1 = np.random.randint(shape_minus_size[0], size=1)[0]\n",
    "            y1 = np.random.randint(shape_minus_size[1], size=1)[0]\n",
    "            if x1 not in set_x and y1 not in set_y:\n",
    "                set_x.add(x1)\n",
    "                set_y.add(y1)\n",
    "                x2 = x1 + self.window\n",
    "                y2 = y1 + self.window\n",
    "                assert x1 < shape_minus_size[0]\n",
    "                assert y1 < shape_minus_size[1]\n",
    "                assert x2 < shape[0]\n",
    "                assert y2 < shape[1]\n",
    "                if mask[x1:x2,y1:y2].sum() > THRESHOLD or np.random.rand() < 0.02:\n",
    "                    self.slices.append([i, x1, x2, y1, y2])\n",
    "                    slice_counter += 1\n",
    "                else:\n",
    "                    self.skipped += 1\n",
    "                        \n",
    "    def apply_transform(self, image, mask):\n",
    "        if self.do_transform:\n",
    "            augments = self.transform(image=image, mask=mask) if self.mode == 'train' else self.valid_transform(image=image, mask=mask)\n",
    "            image = self.as_tensor(augments['image'])\n",
    "            mask = augments['mask'][None]\n",
    "            mask_torch = torch.from_numpy(mask).to(torch.float16)\n",
    "            return image, mask_torch\n",
    "        else:\n",
    "            trfm = A.Compose([\n",
    "                A.Resize(NEW_SIZE, NEW_SIZE)\n",
    "            ])\n",
    "            augments = trfm(image=image, mask=mask)\n",
    "            image = self.as_tensor(augments['image'])\n",
    "            return image, augments['mask'][None]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.slices_path/f'image_{index}'\n",
    "        slices_path = self.slices_path/f'mask_{index}'\n",
    "        if not image_path.exists():\n",
    "            idx = self.slices[index][0]\n",
    "            filename = self.files[idx]\n",
    "            x1, x2, y1, y2 = self.slices[index][1:]\n",
    "            with rasterio.open(filename) as dataset:\n",
    "                layers = extract_layers(dataset, filename)\n",
    "                image = read_from_slice(dataset, layers, x1, x2, y1, y2, self.window).astype('uint8')\n",
    "            mask = self.masks[idx][x1:x2,y1:y2]\n",
    "            with open(image_path, \"wb\") as filehandler:\n",
    "                pickle.dump(image, filehandler)\n",
    "                if index % 100 == 0:\n",
    "                    print(f'Writing to {image_path}')\n",
    "            with open(slices_path, \"wb\") as filehandler:\n",
    "                pickle.dump(mask, filehandler)\n",
    "            return self.apply_transform(image, mask)\n",
    "        else:\n",
    "            with open(image_path,'rb') as file:\n",
    "                image = pickle.load(file)\n",
    "            with open(slices_path,'rb') as file:\n",
    "                mask = pickle.load(file)\n",
    "            return self.apply_transform(image, mask)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'total: {len(self)}, skipped: {self.skipped} mode: {self.mode}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds(size, data_path, slices_path, window):\n",
    "    trfm = A.Compose([\n",
    "        A.Resize(size, size, p=1.0),\n",
    "        A.HorizontalFlip(),\n",
    "        A.VerticalFlip(),\n",
    "        A.RandomRotate90(),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=20, p=0.9, \n",
    "                         border_mode=cv2.BORDER_REFLECT),\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=0.4),\n",
    "            A.GridDistortion(p=.1, border_mode=cv2.BORDER_REFLECT),\n",
    "            A.IAAPiecewiseAffine(p=0.4),\n",
    "        ], p=0.3),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=0.2),\n",
    "            A.MedianBlur(blur_limit=3, p=0.1),\n",
    "            A.Blur(blur_limit=3, p=0.1),\n",
    "        ]),\n",
    "        A.OneOf([\n",
    "            A.HueSaturationValue(10,15,10),\n",
    "            A.CLAHE(clip_limit=3),\n",
    "            A.RandomBrightnessContrast(),\n",
    "            A.RandomGamma()\n",
    "        ], p=0.5)\n",
    "    ], p=1.0)\n",
    "    \n",
    "    valid_transform = A.Compose([\n",
    "        A.Resize(size, size, p=1.0),\n",
    "        A.HorizontalFlip(),\n",
    "        A.VerticalFlip(),\n",
    "        A.RandomRotate90()\n",
    "    ])\n",
    "\n",
    "    return HubDataset(data_path, slices_path, window=window, overlap=MIN_OVERLAP, transform=trfm, valid_transform=valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/rasterio/__init__.py:207: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "  7%|▋         | 1/15 [00:00<00:01,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cached slices, files and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:03<00:00,  4.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "total: 4500, skipped: 0 mode: train"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = generate_ds(NEW_SIZE, DATA_PATH, SLICES_PATH, WINDOW)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1792"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(ds.slices)):\n",
    "    assert ds.slices[i][2] - ds.slices[i][1] == ds.slices[i][4] - ds.slices[i][3] == WINDOW\n",
    "WINDOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 266/1125 [00:16<00:53, 15.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b1987cac1ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mnorm_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_WORKERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mean_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# (tensor([0.0578, 0.0925, 0.0886]), tensor([1.0409, 1.0288, 1.0202]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-b1987cac1ef0>\u001b[0m in \u001b[0;36mget_mean_std\u001b[0;34m(train_dl)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mchannels_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mchannels_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mchannels_squared_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_mean_std(train_dl):\n",
    "    '''\n",
    "    Calculate the mean and std\n",
    "    var = E[x**2] - E[x]**2\n",
    "    '''\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    for data, _ in tqdm(train_dl, total=len(train_dl)):\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_squared_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    assert num_batches == len(train_dl)\n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "    return mean, std\n",
    "\n",
    "ds.do_transform = False\n",
    "norm_dl = D.DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "stats = get_mean_std(norm_dl)\n",
    "stats\n",
    "# (tensor([0.0578, 0.0925, 0.0886]), tensor([1.0409, 1.0288, 1.0202]))\n",
    "# (tensor([0.0578, 0.0925, 0.0886]), tensor([1.0409, 1.0288, 1.0202]))\n",
    "# (tensor([0.0741, 0.1079, 0.1045]), tensor([1.0437, 1.0380, 1.0198]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.do_transform = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_normalize_transform(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mask_img(idx):\n",
    "    image, mask = ds[idx]\n",
    "    mask = mask.to(torch.uint8)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(mask[0], cmap='gray')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.moveaxis(image.numpy(), 0, -1));\n",
    "\n",
    "images_to_display = 25\n",
    "for i in range(images_to_display):\n",
    "    display_mask_img(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.mode = 'valid'\n",
    "\n",
    "for i in range(images_to_display):\n",
    "    display_mask_img(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = ds[0]\n",
    "\n",
    "_ = rle_numba_encode(mask[0].numpy().astype('uint8')) # compile function with numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images and its corresponding masks are saved with the same filename.\n",
    "def generate_fold_info(ds):\n",
    "    groups = [ds.slices[i][0] for i in range(len(ds))]\n",
    "    group_kfold = GroupKFold(n_splits = FOLDS)\n",
    "    fold_info = [(train_idx, valid_idx) for fold, (train_idx, valid_idx) in tqdm(enumerate(group_kfold.split(ds.slices, \n",
    "                                                            groups = groups)), total=FOLDS)]\n",
    "    return fold_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_info = generate_fold_info(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def create_subset(ds, train_idx, valid_idx):\n",
    "    train_ds = D.Subset(ds, train_idx)\n",
    "    val_ds = copy.copy(ds)\n",
    "    val_ds.mode = 'valid'\n",
    "    valid_ds = D.Subset(val_ds, valid_idx)\n",
    "    print(val_ds)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_valid_dls(ds, train_idx, valid_idx):\n",
    "    train_ds, valid_ds = create_subset(ds, train_idx, valid_idx)\n",
    "\n",
    "    num_workers = NUM_WORKERS\n",
    "    # define training and validation data loaders\n",
    "    train_dl = D.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "    valid_dl = D.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuBMAPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HuBMAPModel, self).__init__()\n",
    "        args = {\n",
    "            'encoder_name': ENCODER_NAME, \n",
    "            'encoder_weights': ENCODER_WEIGHTS,\n",
    "            'classes': 2,\n",
    "            'activation': None,\n",
    "            'aux_params': None\n",
    "        }\n",
    "        if ARCH == 'unet':\n",
    "            self.model = Unet(**args)\n",
    "        elif ARCH == 'fpn':\n",
    "            self.model = FPN(**args)\n",
    "        elif ARCH == 'manet':\n",
    "            self.model = MAnet(**args)\n",
    "        elif ARCH == 'linknet':\n",
    "            self.model = Linknet(**args)\n",
    "        elif ARCH == 'pan':\n",
    "            self.model = PAN(**args)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        return self.model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = HuBMAPModel()\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(DEVICE)\n",
    "    model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(model):\n",
    "    return torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "def create_optimizer_scheduler(model, train_dl, epochs):\n",
    "    optimizer = create_optimizer(model)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR,\n",
    "                                                    steps_per_epoch=len(train_dl), epochs=epochs)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = smp.losses.DiceLoss(mode='multiclass', from_logits=True)\n",
    "\n",
    "def loss_fn(y_pred, y_true):\n",
    "    return dice_loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_loss = smp.losses.JaccardLoss(mode='multiclass', from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dls(fold, ds=ds):\n",
    "    train_idx, valid_idx = fold_info[fold]\n",
    "    print(f'Proportions valid / train: {len(valid_idx) / len(train_idx)}')\n",
    "    train_dl, valid_dl = generate_train_valid_dls(ds, train_idx, valid_idx)\n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(fold=0):\n",
    "    train_idx, valid_idx = fold_info[fold]\n",
    "    train_ds, valid_ds = create_subset(ds, train_idx, valid_idx)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0\n",
    "train_ds, valid_ds = create_datasets(FOLD)\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepflash2.all import Iou, Dice_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def forward(self:smp.losses.JaccardLoss, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    \n",
    "#     print('y_pred.shape', y_pred.shape)\n",
    "#     print('y_true.shape', y_true.shape)\n",
    "    \n",
    "    y_true = y_true.long()\n",
    "    \n",
    "    assert y_true.size(0) == y_pred.size(0)\n",
    "\n",
    "    if self.from_logits:\n",
    "        # Apply activations to get [0..1] class probabilities\n",
    "        # Using Log-Exp as this gives more numerically stable result and does not cause vanishing gradient on\n",
    "        # extreme values 0 and 1\n",
    "        if self.mode == MULTICLASS_MODE:\n",
    "            y_pred = y_pred.log_softmax(dim=1).exp()\n",
    "        else:\n",
    "            y_pred = F.logsigmoid(y_pred).exp()\n",
    "\n",
    "    bs = y_true.size(0)\n",
    "    num_classes = y_pred.size(1)\n",
    "    dims = (0, 2)\n",
    "\n",
    "    if self.mode == BINARY_MODE:\n",
    "        y_true = y_true.view(bs, 1, -1)\n",
    "        y_pred = y_pred.view(bs, 1, -1)\n",
    "\n",
    "    if self.mode == MULTICLASS_MODE:\n",
    "        \n",
    "        y_true = y_true.view(bs, -1)\n",
    "        y_pred = y_pred.view(bs, num_classes, -1)\n",
    "        \n",
    "#         print('y_true.shape', y_true.shape)\n",
    "#         print('num_classes', num_classes)\n",
    "        y_true = F.one_hot(y_true, num_classes)  # N,H*W -> N,H*W, C\n",
    "        y_true = y_true.permute(0, 2, 1)  # H, C, H*W\n",
    "\n",
    "    if self.mode == MULTILABEL_MODE:\n",
    "        y_true = y_true.view(bs, num_classes, -1)\n",
    "        y_pred = y_pred.view(bs, num_classes, -1)\n",
    "\n",
    "    scores = soft_jaccard_score(y_pred, y_true.type(y_pred.dtype), smooth=self.smooth, eps=self.eps, dims=dims)\n",
    "\n",
    "    if self.log_loss:\n",
    "        loss = -torch.log(scores.clamp_min(self.eps))\n",
    "    else:\n",
    "        loss = 1.0 - scores\n",
    "\n",
    "    # IoU loss is defined for non-empty classes\n",
    "    # So we zero contribution of channel that does not have true pixels\n",
    "    # NOTE: A better workaround would be to use loss term `mean(y_pred)`\n",
    "    # for this case, however it will be a modified jaccard loss\n",
    "\n",
    "    mask = y_true.sum(dims) > 0\n",
    "    loss *= mask.float()\n",
    "\n",
    "    if self.classes is not None:\n",
    "        loss = loss[self.classes]\n",
    "\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader and learner\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=BATCH_SIZE)\n",
    "if torch.cuda.is_available(): dls.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = f'{FOLD}_best_model'\n",
    "cbs = [SaveModelCallback(monitor='iou', fname=best_model_name), EarlyStoppingCallback(monitor='iou', patience=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, metrics=[Iou(), Dice_f1()], wd=WD, loss_func=jaccard_loss, opt_func=ranger, cbs=cbs)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(EPOCHS, lr_max=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /home/hubmap_notebooks/models/{best_model_name}.pth /home/hubmap_notebooks/models/{FOLD}_{EXPERIMENT_NAME}.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "FOLD = 1\n",
    "train_ds, valid_ds = create_datasets(FOLD)\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader and learner\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=BATCH_SIZE)\n",
    "if torch.cuda.is_available(): dls.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = f'{FOLD}_best_model'\n",
    "cbs = [SaveModelCallback(monitor='dice_metric', fname=best_model_name), EarlyStoppingCallback(monitor='dice_metric', patience=10)]\n",
    "learn = Learner(dls, model, metrics=[Iou(), Dice_f1()], wd=WD, loss_func=loss_fn, opt_func=ranger, cbs=cbs)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(EPOCHS, lr_max=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /home/hubmap_notebooks/models/{best_model_name}.pth /home/hubmap_notebooks/models/{FOLD}_{EXPERIMENT_NAME}.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "FOLD = 2\n",
    "train_ds, valid_ds = create_datasets(FOLD)\n",
    "model = create_model()\n",
    "\n",
    "from fastai.vision.all import *\n",
    "\n",
    "# Dataloader and learner\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=BATCH_SIZE)\n",
    "if torch.cuda.is_available(): dls.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = f'{FOLD}_best_model'\n",
    "cbs = [SaveModelCallback(monitor='dice_metric', fname=best_model_name), EarlyStoppingCallback(monitor='dice_metric', patience=10)]\n",
    "learn = Learner(dls, model, metrics=[dice_metric, iou], wd=WD, loss_func=loss_fn, opt_func=ranger, cbs=cbs)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(EPOCHS, lr_max=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "FOLD = 3\n",
    "train_ds, valid_ds = create_datasets(FOLD)\n",
    "model = create_model()\n",
    "\n",
    "from fastai.vision.all import *\n",
    "\n",
    "# Dataloader and learner\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=BATCH_SIZE)\n",
    "if torch.cuda.is_available(): dls.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = f'{FOLD}_best_model'\n",
    "cbs = [SaveModelCallback(monitor='dice_metric', fname=best_model_name), EarlyStoppingCallback(monitor='dice_metric', patience=10)]\n",
    "learn = Learner(dls, model, metrics=[dice_metric, iou], wd=WD, loss_func=loss_fn, opt_func=ranger, cbs=cbs)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(EPOCHS, lr_max=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /home/hubmap_notebooks/models/{best_model_name}.pth /home/hubmap_notebooks/models/{FOLD}_{EXPERIMENT_NAME}.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir pytorch_models\n",
    "!mv *.pth pytorch_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('/home/hubmap_notebooks/models/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.module.load_state_dict(state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
