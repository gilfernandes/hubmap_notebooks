{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U git+https://github.com/qubvel/segmentation_models.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys, os, random, time, json\n",
    "import numba, cv2, gc\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from segmentation_models_pytorch import FPN\n",
    "from segmentation_models_pytorch import Unet\n",
    "from segmentation_models_pytorch import MAnet\n",
    "from segmentation_models_pytorch import Linknet\n",
    "from segmentation_models_pytorch import PAN\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed = 42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/jupyter/data_2/\n",
    "DATA_PATH = Path('/home/jupyter/data_2/')\n",
    "assert DATA_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/jupyter/data/\n",
    "DATA_PATH_ORIG = Path('/home/jupyter/data/')\n",
    "assert DATA_PATH_ORIG.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_PATH = Path('/home/jupyter/reports')\n",
    "if not REPORT_PATH.exists():\n",
    "    os.makedirs(REPORT_PATH)\n",
    "assert REPORT_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {REPORT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCH = 'linknet' # fpn, manet, linknet, pan\n",
    "\n",
    "WINDOW = 1536 # tile size\n",
    "MIN_OVERLAP = 64\n",
    "NEW_SIZE = 768 # size after re-size which are fed to the model\n",
    "THRESHOLD = 0\n",
    "CONTENT_THRESHOLD = 0.001\n",
    "NUM_WORKERS = 12\n",
    "\n",
    "FOLDS = 4\n",
    "\n",
    "BATCH_SIZE = 12\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "ENCODER_NAME = 'efficientnet-b7'\n",
    "\n",
    "LR = 3e-3\n",
    "WD = 1e-3\n",
    "LABEL_SMOOTH = 0.01\n",
    "GRAD_ACCU_STEPS = 1\n",
    "BEST_MODEL = f'best_model_{ARCH}_efficientnetb7_1536_768_double_shift_{ENCODER_NAME}.pth'\n",
    "\n",
    "RESET_IMAGES = False\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "SLICES_PATH = Path('/home/jupyter/ds_cache')\n",
    "\n",
    "EPOCHS = 20\n",
    "PATIENCE = 5\n",
    "\n",
    "EXPERIMENT_NAME = f'43_pytorch_{ARCH}_efficientnet_b7_1536_768_shifted_slices_groupkfold_smooth_b{BATCH_SIZE}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape=(256, 256)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    splits = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (splits[0:][::2], splits[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype='uint8')\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo: hi] = 1\n",
    "    return img.reshape(shape, order='F') # Fortran order reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def rle_numba(pixels):\n",
    "    size = len(pixels)\n",
    "    points = []\n",
    "    if pixels[0] == 1: points.append(1)\n",
    "    for i in range(1, size):\n",
    "        if pixels[i] != pixels[i-1]:\n",
    "            if len(points) % 2 == 0:\n",
    "                points.append(i+1)\n",
    "            else:\n",
    "                points.append(i+1 - points[-1])\n",
    "    if pixels[-1] == 1: points.append(size-points[-1]+1)    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check run length encoding starting with 0\n",
    "assert rle_numba([0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1]) == [2, 2, 5, 1, 7, 4, 12, 1]\n",
    "# Check run length encoding starting with 0\n",
    "assert rle_numba([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1]) == [1, 3, 5, 1, 7, 4, 12, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_numba_encode(image):\n",
    "    pixels = image.flatten(order = 'F')\n",
    "    points = rle_numba(pixels)\n",
    "    return ' '.join(str(x) for x in points)\n",
    "\n",
    "def make_grid(shape, window=256, min_overlap=32):\n",
    "    \"\"\"\n",
    "        Return Array of size (N,4), where N - number of tiles,\n",
    "        2nd axis represente slices: x1,x2,y1,y2 \n",
    "    \"\"\"\n",
    "    x, y = shape\n",
    "    nx = x // (window - min_overlap) + 1\n",
    "    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n",
    "    x1[-1] = x - window\n",
    "    x2 = (x1 + window).clip(0, x)\n",
    "    ny = y // (window - min_overlap) + 1\n",
    "    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n",
    "    y1[-1] = y - window\n",
    "    y2 = (y1 + window).clip(0, y)\n",
    "    slices = np.zeros((nx,ny, 4), dtype=np.int64)\n",
    "    \n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            slices[i,j] = x1[i], x2[i], y1[j], y2[j]    \n",
    "    return slices.reshape(nx*ny,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH / 'train.csv', index_col=[0])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {SLICES_PATH}\n",
    "!mkdir {SLICES_PATH_ORIG}\n",
    "\n",
    "import shutil\n",
    "\n",
    "def reset_slices_path():\n",
    "    shutil.rmtree(SLICES_PATH)\n",
    "    shutil.rmtree(SLICES_PATH_ORIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Used to filter tiles with enough color information in it\n",
    "def is_tile_contains_info(img, pixel_limits = (50, 220), content_threshold = CONTENT_THRESHOLD, expected_shape = (WINDOW, WINDOW, 3)):\n",
    "    \"\"\"\n",
    "    img: np.array\n",
    "    pixel_limits: tuple\n",
    "    content_threshold: float percents\n",
    "    expected_shape: tuple\n",
    "    \"\"\"\n",
    "    \n",
    "    left_limit = np.prod(img > pixel_limits[0], axis=-1)\n",
    "    right_limit =  np.prod(img < pixel_limits[1], axis=-1)\n",
    "\n",
    "    if img.shape != expected_shape:\n",
    "        print('img.shape != expected_shape', img.shape)\n",
    "        return False, 0.\n",
    "\n",
    "    percent_of_pixels = np.sum(left_limit*right_limit) / (img.shape[0] * img.shape[1])\n",
    "    return  percent_of_pixels > content_threshold, percent_of_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "identity = None\n",
    "# normalize_transform = T.Normalize([0.625, 0.448, 0.688], [0.131, 0.177, 0.101])\n",
    "# normalize_transform = T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# normalize_transform = T.Normalize([0.65459856,0.48386562,0.69428385], [0.15167958,0.23584107,0.13146145])\n",
    "normalize_transform = T.Normalize([0.6276, 0.4468, 0.6769], [0.1446, 0.2113, 0.1233])\n",
    "\n",
    "def read_from_slice(dataset, layers, x1, x2, y1, y2):\n",
    "    if dataset.count == 3:\n",
    "        image = dataset.read([1,2,3],\n",
    "                    window=Window.from_slices((x1,x2),(y1,y2)))\n",
    "        image = np.moveaxis(image, 0, -1)\n",
    "    else:\n",
    "        image = np.zeros((WINDOW, WINDOW, 3), dtype=np.uint8)\n",
    "        for fl in range(3):\n",
    "            image[:,:,fl] = layers[fl].read(window=Window.from_slices((x1,x2),(y1,y2)))\n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "def extract_layers(dataset, filepath):\n",
    "    layers = None\n",
    "    if dataset.count != 3:\n",
    "        layers = [rasterio.open(subd) for subd in dataset.subdatasets]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESET_IMAGES:\n",
    "    reset_slices_path()\n",
    "    !mkdir {SLICES_PATH}\n",
    "    !mkdir {SLICES_PATH_ORIG}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HubDataset(D.Dataset):\n",
    "    def __init__(self, root_dir, slices_path, transform, valid_transform=None, mode='train', window=WINDOW, overlap=MIN_OVERLAP, threshold = THRESHOLD):\n",
    "        self.path, self.slices_path = root_dir, slices_path\n",
    "        assert self.path.exists()\n",
    "        self.overlap, self.window, self.transform, self.valid_transform, self.threshold = overlap, window, transform, valid_transform, threshold\n",
    "        self.mode = mode\n",
    "        self.csv = pd.read_csv(self.path / 'train.csv', index_col=[0])\n",
    "        self.build_slices()\n",
    "        self.len = len(self.slices)\n",
    "        # where do these numbers come from?\n",
    "        # Better to calculate them to check if correct.\n",
    "        self.as_tensor = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            normalize_transform,\n",
    "        ])\n",
    "        \n",
    "    def __copy__(self):\n",
    "        new_ds = type(self)(\n",
    "            self.path,\n",
    "            self.slices_path,\n",
    "            self.transform,\n",
    "            valid_transform=self.valid_transform,\n",
    "            mode=self.mode,\n",
    "            window=self.window,\n",
    "            overlap=self.overlap,\n",
    "            threshold=self.threshold\n",
    "        )\n",
    "        new_ds.masks = self.masks\n",
    "        new_ds.files = self.files\n",
    "        new_ds.slices = self.slices\n",
    "        new_ds.skipped = self.skipped\n",
    "        return new_ds\n",
    "    \n",
    "    def build_masks(self):\n",
    "        for i, filename in tqdm(enumerate(self.csv.index), total = len(self.csv)):\n",
    "            filepath = self.path/'train'/f'{filename}.tiff'\n",
    "            with rasterio.open(filepath) as dataset:\n",
    "                self.masks.append(rle_decode(self.csv.loc[filename, 'encoding'], dataset.shape))\n",
    "        \n",
    "    def build_slices(self):\n",
    "        self.masks = []; self.files = []; self.slices = []\n",
    "        self.skipped = 0\n",
    "        slices_path = self.slices_path/f'slices.pkl'\n",
    "        files_path = self.slices_path/f'files.pkl'\n",
    "        if not slices_path.exists():\n",
    "            for i, filename in tqdm(enumerate(self.csv.index), total = len(self.csv)):\n",
    "                filepath = self.path/'train'/f'{filename}.tiff'\n",
    "                assert filepath.exists()\n",
    "                self.files.append(filepath)\n",
    "                with rasterio.open(filepath) as dataset:\n",
    "                    self.build_slice(dataset, filename, i)\n",
    "                print(f'Finished {filename}')\n",
    "            with open(slices_path, \"wb\") as filehandler:\n",
    "                pickle.dump(self.slices, filehandler)\n",
    "            with open(files_path, \"wb\") as filehandler:\n",
    "                pickle.dump(self.files, filehandler)\n",
    "            \n",
    "        else:\n",
    "            print('Reading cached slices, files and masks')\n",
    "            with open(slices_path,'rb') as file:\n",
    "                self.slices = pickle.load(file)\n",
    "            with open(files_path,'rb') as file:\n",
    "                self.files = pickle.load(file)\n",
    "        self.build_masks()\n",
    "                \n",
    "    def build_slice(self, dataset, filename, i):\n",
    "        dataset_shape = dataset.shape\n",
    "        self.masks.append(rle_decode(self.csv.loc[filename, 'encoding'], dataset_shape))\n",
    "        slices = make_grid(dataset_shape, window = self.window, min_overlap = self.overlap)\n",
    "\n",
    "        # Shifting slices to the right and bottom and adding to the original slices\n",
    "        slices_copy = slices.copy()\n",
    "        slices_copy_y = slices.copy()\n",
    "#         # horizontal\n",
    "        slices_copy[:,(0,1)] += WINDOW // 2 # shift\n",
    "        slices = np.concatenate ([slices, slices_copy])\n",
    "#         # vertical\n",
    "        slices_copy_y[:,(2,3)] += WINDOW // 2\n",
    "        slices = np.concatenate ([slices, slices_copy_y])\n",
    "        slices = slices[~(slices[:,1] > dataset_shape[0]),:] # filter those outside of the screen\n",
    "        slices = slices[~(slices[:,3] > dataset_shape[1]),:] # filter those outside of the screen\n",
    "        \n",
    "        layers = extract_layers(dataset, filename)\n",
    "        \n",
    "        # Only including slices above a specific threshold\n",
    "        # Note: we are potentially throwing away some data here\n",
    "        for slc in slices:\n",
    "            x1, x2, y1, y2 = slc\n",
    "            image = read_from_slice(dataset, layers, x1, x2 , y1, y2)\n",
    "#             contains_info = is_tile_contains_info(image)\n",
    "#             if self.masks[-1][x1:x2,y1:y2].sum() > self.threshold and contains_info[0]:\n",
    "            if self.masks[-1][x1:x2,y1:y2].sum() > self.threshold:\n",
    "                self.slices.append([i,x1,x2,y1,y2])\n",
    "            else:\n",
    "                self.skipped += 1\n",
    "                        \n",
    "                        \n",
    "    def apply_transform(self, image, mask):\n",
    "        augments = self.transform(image=image, mask=mask) if self.mode == 'train' else self.valid_transform(image=image, mask=mask)\n",
    "        image = self.as_tensor(augments['image'])\n",
    "        mask = augments['mask'][None]\n",
    "        mask_torch = torch.from_numpy(mask).to(torch.float16)\n",
    "        return image, mask_torch\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.slices_path/f'image_{index}'\n",
    "        slices_path = self.slices_path/f'mask_{index}'\n",
    "        if not image_path.exists():\n",
    "            idx = self.slices[index][0]\n",
    "            filename = self.files[idx]\n",
    "            x1, x2, y1, y2 = self.slices[index][1:]\n",
    "            with rasterio.open(filename) as dataset:\n",
    "                layers = extract_layers(dataset, filename)\n",
    "                image = read_from_slice(dataset, layers, x1, x2, y1, y2).astype('uint8')\n",
    "            mask = self.masks[idx][x1:x2,y1:y2]\n",
    "            with open(image_path, \"wb\") as filehandler:\n",
    "                pickle.dump(image, filehandler)\n",
    "                if index % 100 == 0:\n",
    "                    print(f'Writing to {image_path}')\n",
    "            with open(slices_path, \"wb\") as filehandler:\n",
    "                pickle.dump(mask, filehandler)\n",
    "            return self.apply_transform(image, mask)\n",
    "        else:\n",
    "            with open(image_path,'rb') as file:\n",
    "                image = pickle.load(file)\n",
    "            with open(slices_path,'rb') as file:\n",
    "                mask = pickle.load(file)\n",
    "            return self.apply_transform(image, mask)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'total: {len(self)}, skipped: {self.skipped} mode: {self.mode}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds(size, data_path, slices_path):\n",
    "    trfm = A.Compose([\n",
    "        A.Resize(size, size, p=1.0),\n",
    "        A.HorizontalFlip(),\n",
    "        A.VerticalFlip(),\n",
    "        A.RandomRotate90(),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=20, p=0.9, \n",
    "                         border_mode=cv2.BORDER_REFLECT),\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=0.4),\n",
    "            A.GridDistortion(p=.1, border_mode=cv2.BORDER_REFLECT),\n",
    "            A.IAAPiecewiseAffine(p=0.4),\n",
    "        ], p=0.3),\n",
    "        A.OneOf([\n",
    "            A.HueSaturationValue(10,15,10),\n",
    "            A.CLAHE(clip_limit=3),\n",
    "            A.RandomBrightnessContrast(),\n",
    "            A.RandomGamma()\n",
    "        ], p=0.5)\n",
    "    ], p=1.0)\n",
    "    \n",
    "    valid_transform = A.Compose([\n",
    "        A.Resize(size, size, p=1.0),\n",
    "        A.HorizontalFlip(),\n",
    "        A.VerticalFlip(),\n",
    "        A.RandomRotate90()\n",
    "    ])\n",
    "\n",
    "    return HubDataset(data_path, slices_path, window=WINDOW, overlap=MIN_OVERLAP, transform=trfm, valid_transform=valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = generate_ds(NEW_SIZE, DATA_PATH, SLICES_PATH)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mask_img(idx):\n",
    "    image, mask = ds[idx]\n",
    "    mask = mask.to(torch.uint8)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(mask[0], cmap='gray')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.moveaxis(image.numpy(), 0, -1));\n",
    "\n",
    "for i in range(5):\n",
    "    display_mask_img(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.mode = 'valid'\n",
    "\n",
    "for i in range(5):\n",
    "    display_mask_img(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = ds[0]\n",
    "\n",
    "_ = rle_numba_encode(mask[0].numpy().astype('uint8')) # compile function with numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images and its corresponding masks are saved with the same filename.\n",
    "def generate_fold_info(ds):\n",
    "    groups = [ds.slices[i][0] for i in range(len(ds))]\n",
    "    group_kfold = GroupKFold(n_splits = FOLDS)\n",
    "    fold_info = [(train_idx, valid_idx) for fold, (train_idx, valid_idx) in tqdm(enumerate(group_kfold.split(ds.slices, \n",
    "                                                            groups = groups)), total=FOLDS)]\n",
    "    return fold_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_info = generate_fold_info(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def create_subset(ds, train_idx, valid_idx):\n",
    "    train_ds = D.Subset(ds, train_idx)\n",
    "    val_ds = copy.copy(ds)\n",
    "    val_ds.mode = 'valid'\n",
    "    valid_ds = D.Subset(val_ds, valid_idx)\n",
    "    print(val_ds)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_valid_dls(ds, train_idx, valid_idx):\n",
    "    train_ds, valid_ds = create_subset(ds, train_idx, valid_idx)\n",
    "\n",
    "    num_workers = NUM_WORKERS\n",
    "    # define training and validation data loaders\n",
    "    train_dl = D.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "    valid_dl = D.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuBMAPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HuBMAPModel, self).__init__()\n",
    "        args = {\n",
    "            'encoder_name': ENCODER_NAME, \n",
    "            'encoder_weights': ENCODER_WEIGHTS,\n",
    "            'classes': 1,\n",
    "            'activation': None,\n",
    "            'aux_params': None\n",
    "        }\n",
    "        if ARCH == 'unet':\n",
    "            self.model = Unet(**args)\n",
    "        elif ARCH == 'fpn':\n",
    "            self.model = FPN(**args)\n",
    "        elif ARCH == 'manet':\n",
    "            self.model = MAnet(**args)\n",
    "        elif ARCH == 'linknet':\n",
    "            self.model = Linknet(**args)\n",
    "        elif ARCH == 'pan':\n",
    "            self.model = PAN(**args)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        return self.model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = HuBMAPModel()\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(DEVICE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer_scheduler(model, train_dl, epochs):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR,\n",
    "                                                    steps_per_epoch=len(train_dl), epochs=epochs)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1., dims=(-2,-1)):\n",
    "\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.dims = dims\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "\n",
    "        tp = (x * y).sum(self.dims)\n",
    "        fp = (x * (1 - y)).sum(self.dims)\n",
    "        fn = ((1 - x) * y).sum(self.dims)\n",
    "        \n",
    "        dc = (2 * tp + self.smooth) / (2 * tp + fp + fn + self.smooth)\n",
    "        dc = dc.mean()\n",
    "\n",
    "        return 1 - dc\n",
    "    \n",
    "bce_fn = nn.BCEWithLogitsLoss()\n",
    "dice_fn = SoftDiceLoss()\n",
    "\n",
    "def loss_fn(y_pred, y_true):\n",
    "    bce = bce_fn(y_pred, y_true)\n",
    "    dice = dice_fn(y_pred.sigmoid(), y_true)\n",
    "    return 0.5 * bce + 0.5 * dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = smp.losses.DiceLoss(mode='binary', from_logits=False)\n",
    "\n",
    "def loss_fn(y_pred, y_true):\n",
    "    return dice_loss(y_pred.sigmoid(), y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_ALPHA = 0.4\n",
    "\n",
    "def loss_fn(y_pred, y_true):\n",
    "    return LOSS_ALPHA * dice_loss(y_pred.sigmoid(), y_true) + (1 - LOSS_ALPHA) * bce_fn(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaccard_loss = smp.utils.losses.JaccardLoss()\n",
    "\n",
    "# def loss_fn(y_pred, y_true):\n",
    "#     return jaccard_loss(y_pred.sigmoid(), y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_metric(y_pred, y, epsilon = 1e-7):\n",
    "    dims=(-2,-1)\n",
    "    x = (y_pred > 0).float()\n",
    "    dc = (2 * (x * y).sum(dims) + epsilon) / ((x + y).sum(dims) + epsilon)\n",
    "    return dc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_metric = smp.utils.metrics.IoU(threshold=0.5)\n",
    "dice_metric_2 = smp.utils.metrics.Fscore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "# def smooth_mask(mask, alpha = 0.9):\n",
    "#     zeros_mask = (mask == 0).to(torch.float16) * (1 - alpha)\n",
    "#     mask = mask * alpha\n",
    "#     return mask + zeros_mask\n",
    "\n",
    "def smooth_mask_2(mask, alpha = LABEL_SMOOTH):\n",
    "    return (1 - alpha) * mask + alpha / 2\n",
    "\n",
    "def train_epoch(model, dataloader, optim, criterion, scheduler, device=\"cpu\", grad_accu_steps=GRAD_ACCU_STEPS):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = []\n",
    "    labels = []\n",
    "    outs = []\n",
    "    lrs = []\n",
    "    \n",
    "    tbar = tqdm(dataloader, position=0, leave=True)\n",
    "    scaler = torch.cuda.amp.GradScaler() # mixed precision support\n",
    "    scale = None\n",
    "    for step, (image, target) in enumerate(tbar):\n",
    "        image, target = image.to(DEVICE), target.float().to(DEVICE)\n",
    "        target = smooth_mask_2(target)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target) / grad_accu_steps\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        if (step + 1) % grad_accu_steps == 0:\n",
    "            scaler.step(optim)\n",
    "            scale = scaler.get_scale()\n",
    "            scaler.update()\n",
    "            optim.zero_grad()\n",
    "        \n",
    "        skip_lr_sched = (scale != scaler.get_scale())\n",
    "        if not skip_lr_sched:\n",
    "            scheduler.step()\n",
    "        \n",
    "        loss_val = loss.item() * grad_accu_steps\n",
    "        train_loss.append(loss_val)\n",
    "        lrs.append(get_lr(optim))\n",
    "        \n",
    "        tbar.set_description('loss - {:.4f}'.format(loss_val))\n",
    "        \n",
    "    print(f'Train loss: {np.array(train_loss).mean()}')\n",
    "    return train_loss, lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = [dice_metric, dice_metric_2, iou_metric]\n",
    "\n",
    "def val_epoch(model, dataloader, criterion, epoch, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    valid_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "    metric_list = [[] for _ in all_metrics]\n",
    "\n",
    "    for item in dataloader:\n",
    "        image, target = item\n",
    "        image, target = image.to(DEVICE), target.float().to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "            for ml, m in zip(metric_list, all_metrics):\n",
    "                ml.append(m(output, target).item())\n",
    "        valid_loss.append(loss.item())\n",
    "\n",
    "    avg_loss = np.array(valid_loss).mean()\n",
    "    print(f'Epoch {epoch} - valid loss: {avg_loss}')\n",
    "    dice_metric_mean = np.array(metric_list[0]).mean()\n",
    "    dice_metric_mean_2 = np.array(metric_list[1]).mean()\n",
    "    iou_metric_mean = np.array(metric_list[2]).mean()\n",
    "    return valid_loss, dice_metric_mean, avg_loss, iou_metric_mean, dice_metric_mean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fold, epochs, train_dl, valid_dl, optimizer, scheduler, patience = 6):\n",
    "    best_loss = 100.0\n",
    "    best_metric = 0\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    accumulated_lrs = []\n",
    "    accumulated_dice_metrics = []\n",
    "    early_stop_counter = 0\n",
    "    messages = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), position=0, leave=True):\n",
    "        train_loss, lrs = train_epoch(model, train_dl, optimizer, loss_fn, scheduler, DEVICE)\n",
    "        valid_loss, dice_metric_mean, avg_loss, iou_metric_mean, dice_metric_mean_2 = val_epoch(model, valid_dl, loss_fn, epoch, DEVICE)\n",
    "        train_losses += train_loss\n",
    "        valid_losses.append(np.array(valid_loss).mean())\n",
    "        accumulated_lrs += lrs\n",
    "        accumulated_dice_metrics.append(dice_metric_mean)\n",
    "        if best_metric < dice_metric_mean:\n",
    "            best_metric = dice_metric_mean\n",
    "            print('Saving model')\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                torch.save(model.module.state_dict(), BEST_MODEL)\n",
    "            else:\n",
    "                torch.save(model.state_dict(), BEST_MODEL)\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "        if best_loss > avg_loss:\n",
    "            best_loss = avg_loss\n",
    "        print(f'Epoch {epoch} - val best loss {best_loss} dice metric ({dice_metric_mean}, {dice_metric_mean_2}) iou metric ({iou_metric_mean}).')\n",
    "        messages.append({\n",
    "            'fold': fold,\n",
    "            'epoch': epoch,\n",
    "            'avg_loss': avg_loss,\n",
    "            'best_loss': best_loss,\n",
    "            'dice_metric_mean': dice_metric_mean,\n",
    "            'dice_coeff_mean': dice_metric_mean_2,\n",
    "            'iou_metric_mean': iou_metric_mean\n",
    "        })\n",
    "        with open(REPORT_PATH/f'{EXPERIMENT_NAME}_fold_{fold}', 'w') as outfile:\n",
    "            json.dump(messages, outfile)\n",
    "        if early_stop_counter >= patience:\n",
    "            print('Stopping early')\n",
    "            break\n",
    "    \n",
    "    return train_losses, valid_losses, accumulated_lrs, accumulated_dice_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm sample_weights_model_efficientnet_b7.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_split(fold_info, fold):\n",
    "    global model\n",
    "    \n",
    "    print(f'Processing fold {fold}')\n",
    "    model = get_model()\n",
    "    train_idx, valid_idx = fold_info[fold]\n",
    "    print(f'Proportions valid / train: {len(valid_idx) / len(train_idx)}')\n",
    "    train_dl, valid_dl = generate_train_valid_dls(ds, train_idx, valid_idx)\n",
    "    optimizer, scheduler = create_optimizer_scheduler(model, train_dl, EPOCHS)\n",
    "    train_losses, valid_losses, accumulated_lrs, accumulated_dice_metrics = train(fold, EPOCHS, train_dl, valid_dl, optimizer, scheduler, patience = PATIENCE)\n",
    "    return train_losses, valid_losses, accumulated_lrs, accumulated_dice_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.data.core import DataLoaders\n",
    "\n",
    "# train_idx, valid_idx = fold_info[0]\n",
    "# train_ds, valid_ds = create_subset(ds, train_idx, valid_idx)\n",
    "\n",
    "# dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=BATCH_SIZE, num_workers=0)\n",
    "# assert(dls.bs == BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model()\n",
    "# metrics = [dice_metric, dice_metric_2, iou_metric]\n",
    "# criterion = loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.vision.all import Learner\n",
    "# from fastai.callback.fp16 import *\n",
    "\n",
    "# learn = Learner(dls, model, loss_func=criterion, lr=LR, metrics=metrics, cbs=[MixedPrecision])\n",
    "# learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# learn.fit_one_cycle(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idx, valid_idx = fold_info[0]\n",
    "# train_dl, valid_dl = generate_train_valid_dls(ds, train_idx, valid_idx)\n",
    "# for image, target in tqdm(train_dl):\n",
    "#     pass\n",
    "# #     assert image.shape[0] > 1\n",
    "# for image, target in tqdm(valid_dl):\n",
    "#     pass\n",
    "# #     assert image.shape[0] > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_split_and_move(fold_info, fold):\n",
    "    train_losses, valid_losses, accumulated_lrs, accumulated_dice_metrics = train_split(fold_info, fold)\n",
    "    !mv {BEST_MODEL} {fold}_{BEST_MODEL}\n",
    "    stats_df = pd.DataFrame({'train_losses': train_losses, 'accumulated_lrs': accumulated_lrs})\n",
    "    stats_df[['train_losses']].plot()\n",
    "    val_stats_df = pd.DataFrame({'valid_losses': valid_losses})\n",
    "    val_stats_df[['valid_losses']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_split_and_move(fold_info, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_split_and_move(fold_info, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_split_and_move(fold_info, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_split_and_move(fold_info, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir models\n",
    "!mv *.pth models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
